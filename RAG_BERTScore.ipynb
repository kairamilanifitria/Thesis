{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install transformers bert_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGEJestJMryI",
        "outputId": "ce4e261f-e41a-4719-cc9c-3df4a189dd03"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: bert_score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.1.0+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2023.3.post1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert_score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Journal 1**"
      ],
      "metadata": {
        "id": "n1EyO-gvOvIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"pip install flair\",\n",
        "              \"FLAIR framework\",\n",
        "              \"https://github.com/zalandoresearch/flair\",\n",
        "              \"Presented FLAIR as a framework designed to facilitate experimentation with different embedding types, as well as training and distributing sequence labeling and text classification models.\",\n",
        "              \"at least version 3.6 of Python\"]"
      ],
      "metadata": {
        "id": "wyEcYRYAHwNv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The command for installing the FLAIR library is pip install flair\",\n",
        "              \"The proposed solution from this paper is the FLAIR framework. It is designed to address the challenges of working with different types of word embeddings. The framework provides a unified interface for all word embeddings and allows researchers to build a single model architecture that can make use of any type of word embedding with no additional engineering effort. It also includes convenience methods for downloading NLP research datasets, model training routines, and pre-trained models. The FLAIR framework aims to simplify the process of setting up and executing experiments in natural language processing.\",\n",
        "              \"The GitHub link for the FLAIR framework is: https://github.com/zalandoresearch/flair\",\n",
        "              \"The purpose of the presented framework, called FLAIR, is to address the challenges of using different types of word embeddings in natural language processing (NLP) tasks. The framework aims to abstract away from specific engineering challenges and provide a unified interface for all word embeddings. It allows researchers to build a single model architecture that can make use of any type of word embedding with no additional engineering effort. The framework also includes convenience methods for downloading NLP datasets, model training and hyperparameter selection routines, and a growing list of pre-trained models. Overall, the framework is designed to facilitate experimentation with different embedding types and training and distributing sequence labeling and text classification models.\",\n",
        "              \"The minimum version of Python required to set up FLAIR in the environment is Python 3.6.\"]\n"
      ],
      "metadata": {
        "id": "uRog_MulIEl2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"The command to install the FLAIR library is pip install flair. FLAIR is a powerful natural language processing library that provides pre-trained models and tools for various NLP tasks, including named entity recognition (NER) . By running the pip install flair command, the FLAIR library and its dependencies will be automatically downloaded and installed in the Python environment . This command requires an active internet connection to access the Python Package Index (PyPI) and retrieve the FLAIR package . Once installed, FLAIR can be imported into Python scripts or notebooks using the import flair statement, allowing users to leverage its functionalities for NLP tasks, including NER in the biomedical domain.\",\n",
        "                     \"The proposed solution from the paper is a natural language processing (NLP) framework called FLAIR (Framework for Learning and Information Extraction). FLAIR utilizes state-of-the-art deep learning techniques, such as bidirectional LSTMs and contextual string embeddings, to achieve high-performance results in various NLP tasks, including named entity recognition (NER). The framework is designed to be user-friendly and provides pre-trained models and tools for NLP tasks. FLAIR offers compatibility with different operating systems, including Windows, macOS, and Linux, and requires a minimum Python version of 3.6 or higher. By installing the FLAIR library using the pip install flair command, users can access the functionalities of the framework and leverage its pre-trained models for NER and other NLP tasks.\",\n",
        "                     \"The GitHub link for the FLAIR framework is https://github.com/flairNLP/flair . The FLAIR GitHub repository provides access to the source code, documentation, and examples for using the FLAIR library in natural language processing tasks . Users can clone or download the FLAIR repository from the provided GitHub link to get the latest version of the framework . The repository contains information on how to install FLAIR, as well as tutorials and examples to help users get started with using the framework for NLP tasks . Additionally, the FLAIR GitHub repository allows users to contribute to the development of the framework by submitting issues or pull requests.\",\n",
        "                     \"The presented framework is used for natural language processing (NLP) tasks, specifically named entity recognition (NER) and other NLP tasks. The framework, called FLAIR (Framework for Learning and Information Extraction), utilizes deep learning techniques, such as bidirectional LSTMs and contextual string embeddings, to achieve high-performance results in NLP tasks. FLAIR provides pre-trained models and tools for NLP tasks, making it user-friendly and accessible for researchers and practitioners. The framework is compatible with different operating systems, including Windows, macOS, and Linux, and can be installed using the pip install flair command. The FLAIR GitHub repository (https://github.com/flairNLP/flair) contains the source code, documentation, and examples for using the FLAIR library in NLP tasks, allowing users to clone or download the repository to access the latest version of the framework. Users can contribute to the development of FLAIR by submitting issues or pull requests through the GitHub repository.\",\n",
        "                     \"The minimum Python version required to set up FLAIR in the environment is Python 3.6 or higher. FLAIR is compatible with different operating systems, including Windows, macOS, and Linux. To install FLAIR, users can use the \"\"pip install flair\"\" command, which will automatically install the required dependencies. FLAIR provides pre-trained models and tools for natural language processing (NLP) tasks, such as named entity recognition (NER).The FLAIR GitHub repository (https://github.com/flairNLP/flair) contains the source code, documentation, and examples for using the FLAIR library in NLP tasks. Users can contribute to the development of FLAIR by submitting issues or pull requests through the GitHub repository\"]"
      ],
      "metadata": {
        "id": "KK3YWs0UM0fk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUspfYQYHffm",
        "outputId": "8b3d771c-ed3b-4f72-a6bf-0f7c13f2c55b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8616, Recall: 0.9111, F1: 0.8856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTTjmteRXWcz",
        "outputId": "8e7b23a6-2cdf-4725-b4c9-308772ae4371"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.7894, Recall: 0.8635, F1: 0.8247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Journal 2**"
      ],
      "metadata": {
        "id": "K0yYK1DaO89m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"Edge Probing\",\n",
        "              \"Scalar Mixing Weights, and Cumulative Scoring\",\n",
        "              \"ELMo model\",\n",
        "              \"BERT model\",\n",
        "              \"to measure how well information about linguistic structure can be extracted from a pre-trained encoder\"]"
      ],
      "metadata": {
        "id": "U4cWXQvLO6JM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The experiment is based on the edge probing task suite, which is used to explore how different layers of the BERT network can resolve syntactic and semantic structure within a sentence.\",\n",
        "              \"The two metrics used in this experiment are scalar mixing weights and cumulative scoring.\",\n",
        "              \"The scalar mixing technique was introduced by the ELMo model.\",\n",
        "              \"The language model used in this paper is BERT (Bidirectional Encoder Representations from Transformers), as mentioned in the text: We build on this latter line of work, focusing on the BERT model (Devlin et al., 2018).\",\n",
        "              \"The main purpose of the edge probing task suite is to explore how the different layers of the BERT network can resolve syntactic and semantic structure within a sentence. It aims to measure how well the BERT network can extract information about linguistic structure and how it represents language.\"]"
      ],
      "metadata": {
        "id": "vB94Pu_DbdNw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"The experiments in the provided papers are based on the following methods: The experiments utilize a deep learning framework called FLAIR (Framework for Learning and Information Extraction) for natural language processing (NLP) tasks. FLAIR incorporates bidirectional LSTMs and contextual string embeddings to achieve high-performance results in NLP tasks. The framework provides pre-trained models and tools for NLP tasks, making it user-friendly and accessible for researchers and practitioners. FLAIR is compatible with different operating systems, including Windows, macOS, and Linux, and can be installed using the \"\"pip install flair\"\" command. The FLAIR GitHub repository contains the source code, documentation, and examples for using the FLAIR library in NLP tasks, allowing users to clone or download the repository to access the latest version of the framework. Users can contribute to the development of FLAIR by submitting issues or pull requests through the GitHub repository.\",\n",
        "              \"Two metrics used in the experiments are precision and recall. Precision is a metric that measures the proportion of correctly predicted positive instances out of all instances predicted as positive. Recall, also known as sensitivity, measures the proportion of correctly predicted positive instances out of all actual positive instances. Precision and recall are commonly used evaluation metrics in information retrieval and machine learning tasks, including natural language processing (NLP). These metrics provide insights into the performance of the models and algorithms used in the experiments, helping to assess their effectiveness in tasks such as named entity recognition (NER) and other NLP tasks.\",\n",
        "              \"The model that introduced the scalar mixing technique is the Transformer-XL model. Transformer-XL is a variant of the Transformer model that addresses the limitation of the original Transformer's fixed-length context window. The scalar mixing technique is introduced in the context of modeling long-range dependencies in sequential data. The scalar mixing technique allows the model to capture dependencies between distant positions in the input sequence by incorporating information from previous segments of the sequence. This technique involves using a set of learned scalars to combine the hidden states from different segments of the input sequence. By incorporating the scalar mixing technique, Transformer-XL achieves improved performance in tasks that require modeling long-range dependencies, such as language modeling and machine translation.\",\n",
        "              \"The language model used in this paper is BERT (Bidirectional Encoder Representations from Transformers). BERT is a deep language model that has shown state-of-the-art performance on various natural language processing (NLP) tasks. BERT is based on the Transformer architecture and is trained with a multi-task objective, including masked language modeling and next-sentence prediction. The BERT model used in this paper is the stock BERT model, which includes both the base and large versions. The encoder weights of the BERT model are frozen in this paper, following the approach of Tenney et al. (2019), to understand the structure of the network resulting from pretraining.\",\n",
        "              \"The main purpose of edge probing is to measure how well a pre-trained encoder can extract information about linguistic structure. Edge probing decomposes structured-prediction tasks into a common format, where a probing classifier receives spans and must predict a label such as a constituent or relation type. The probing classifier has access only to the per-token contextual vectors within the target spans, relying on the encoder to provide information about the relation between these spans and their role in the sentence. Edge probing allows for the evaluation of different linguistic properties, such as part-of-speech, constituents, dependencies, entities, semantic role labeling, coreference, semantic proto-roles, and relation classification. The edge probing approach provides insights into the capabilities of pre-trained encoders in capturing linguistic structure and helps in understanding the decision-making process of the model.\"]"
      ],
      "metadata": {
        "id": "SoKUAuE5bdUy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "id": "qHJ5QWRsReON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8b9e2f-9c0c-4732-d5ed-c726b8c28af0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8387, Recall: 0.8836, F1: 0.8605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRJtckjObVwl",
        "outputId": "a033544a-33b2-44af-9d81-ad8a93f12075"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.7879, Recall: 0.8440, F1: 0.8146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Journal 3**"
      ],
      "metadata": {
        "id": "jc80P8pROviy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"perform an analysis of the energy required to train a variety of popular off the-shelf NLP models, as well as a case study of the complete sum of resources required to develop LISA, a state-of-the-art NLP model from EMNLP 2018, including all tuning and experimentation.\",\n",
        "              \"Transformer base model was trained for 12 hours, and Transformer big model was trained for 3.5 days\",\n",
        "              \"Yes, Of note is that TPUs are more cost-efficient than GPUs on workloads that make sense for that hardware\",\n",
        "              \"NVIDIA Titan X GPU, and Intelâ€™s Running Average Power Limit interface CPU\",\n",
        "              \"Transformers, ELMo, BERT, GPT-2\"]"
      ],
      "metadata": {
        "id": "3pJGRK6RduCE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"In this research, the authors conducted an analysis to quantify the computational and environmental costs of training deep neural network models for NLP. They performed experiments to measure the energy consumed during the training of various popular off-the-shelf NLP models. The models were trained using default settings and on specific hardware (such as NVIDIA Titan X GPU and NVIDIA GTX 1080 Ti GPUs). The authors also sampled the power consumption of the GPU and CPU during training. Additionally, they conducted a case study to estimate the complete sum of resources required to develop a state-of-the-art NLP model called LISA.\",\n",
        "              \"The training time for the Transformer base model on NVIDIA P100 GPUs is 12 hours, while the training time for the Transformer big model on NVIDIA P100 GPUs is 84 hours.\",\n",
        "              \"Yes, according to the analysis in Table 3, TPUs are more cost-efficient than GPUs for certain workloads, such as training BERT.\",\n",
        "              \"The models in this experiment were trained using a combination of NVIDIA Titan X (72%) and M40 (28%) GPUs. Unfortunately, the specific CPU used for training is not mentioned in the given context.\",\n",
        "              \"The four models used in this experiment are: Transformer: An encoder-decoder architecture primarily used for machine translation, Language models: Unsupervised multitask learners, Practical Bayesian optimization of machine learning algorithms, Linguistically-Informed Self-Attention for Semantic Role Labeling.\"]"
      ],
      "metadata": {
        "id": "Upimx0U0O3tK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"In this research, the authors conducted an analysis to quantify the computational and environmental costs of training deep neural network models for NLP. They performed experiments to measure the energy consumed during the training of various popular off-the-shelf NLP models. The models were trained using default settings and on specific hardware (such as NVIDIA Titan X GPU and NVIDIA GTX 1080 Ti GPUs). The authors also sampled the power consumption of the GPU and CPU during training. Additionally, they conducted a case study to estimate the complete sum of resources required to develop a state-of-the-art NLP model called LISA.\",\n",
        "              \"The Transformer base model, with 65M parameters, was trained on 8 NVIDIA P100 GPUs for 12 hours . The Transformer big model, with 213M parameters, was trained on 8 NVIDIA P100 GPUs for 3.5 days (84 hours; 300k steps).\",\n",
        "              \"According to the analysis in Table 3, TPUs are more cost-efficient than GPUs on workloads that are suitable for TPUs, such as BERT models. The analysis compared the CO2 emissions and estimated cost of training models using TPUs and GPUs. The research found that training BERT on a GPU is equivalent to the carbon emissions of a trans-American flight, highlighting the substantial carbon emissions associated with training models on GPUs. However, it is important to note that the analysis in Table 3 did not include power and carbon footprint information for TPUs due to a lack of public information. Therefore, while TPUs are shown to be more cost-efficient than GPUs for certain workloads, a comprehensive comparison of their environmental costs is not available in the provided sources.\",\n",
        "              \"The models in the experiment were trained on a single NVIDIA Titan X GPU, except for the ELMo model which was trained on 3 NVIDIA GTX 1080 Ti GPUs. The GPU power consumption was sampled using the NVIDIA System Management Interface. The CPU power consumption was sampled using Intel's Running Average Power Limit interface. The research also used a combination of NVIDIA Titan X (72) and M40 (28) GPUs for model training associated with the project. The training for the Linguistically-Informed Self-Attention model spanned a period of 172 days, with various job lengths ranging from 3 minutes to 9 days.\",\n",
        "              \"The four models used in this experiment are the Transformer model, the BERT model, the ELMo model, and the Linguistically-Informed Self-Attention model.\"]"
      ],
      "metadata": {
        "id": "q3G902WfO3w8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiVVBGW_bUF6",
        "outputId": "69c00fc3-b7ae-42c1-ba6f-7a9c1e3f0518"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8570, Recall: 0.8867, F1: 0.8715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnzmcNydbUIa",
        "outputId": "3c15c62f-dffb-4159-e082-efa5cc41e230"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8457, Recall: 0.9035, F1: 0.8735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Journal 4**"
      ],
      "metadata": {
        "id": "Uc27MLdxPFD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"brat rapid annotation tool is an intuitive web-based tool for text annotation supported by Natural Language Processing (NLP) technology\",\n",
        "              \"well-over 50,000 annotations\",\n",
        "              \"http://brat.nlplab.org\",\n",
        "              \"client-server architecture with communication over HTTP using JavaScript Object Notation (JSON)\",\n",
        "              \"15.4%\"]"
      ],
      "metadata": {
        "id": "7G7NcDC7PHso"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"BRAT is a web-based tool for text annotation supported by Natural Language Processing (NLP) technology. It is designed to assist in manual curation efforts and increase annotator productivity using NLP techniques. BRAT allows for rich structured annotation for a variety of NLP tasks and is fully configurable to support most text annotation tasks. It supports basic annotation primitives, such as identifying text spans and assigning them types, as well as connecting annotations with binary relations. BRAT also supports n-ary associations of annotations and the marking of attributes. It includes a search feature for browsing annotations and can be extended or adapted to switch out the server or client. BRAT is available under an open-source license.\",\n",
        "              \"BRAT has been used in several ongoing annotation efforts at academic institutions and has created well-over 50,000 annotations.\",\n",
        "              \"The homepage link for the free open-source BRAT is http://brat.nlplab.org.\",\n",
        "              \"BRAT is implemented using a client-server architecture with communication over HTTP using JavaScript Object Notation (JSON). The server is a RESTful web service and the client user interface is implemented using XHTML and Scalable Vector Graphics (SVG), with interactivity implemented using JavaScript with the jQuery library. The client communicates with the server using Asynchronous JavaScript and XML (AJAX).\",\n",
        "              \"The experiment resulted in a 15.4% reduction in total annotation time.\"]"
      ],
      "metadata": {
        "id": "NdbE7OwyPJbJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"BRAT is a web-based tool for text annotation that is supported by Natural Language Processing (NLP) technology. It aims to enhance annotator productivity and supports manual curation efforts. It is designed to facilitate rich structured annotation for various NLP tasks and has been used in real-world annotation projects, showing a decrease in annotation time. BRAT uses a client-server architecture with communication over HTTP using JSON. The client user interface is implemented using XHTML and SVG, with interactivity implemented using JavaScript and jQuery. The server is a RESTful web service implemented in Python. BRAT supports both the Common Gateway Interface (CGI) and FastCGI protocols for efficient response times and uses a file-based stand-off format for annotation storage, eliminating the need for database import or export. \",\n",
        "              \"BRAT has created well-over 50,000 annotations in its use at academic institutions.\",\n",
        "              \"BRAT, the free open-source tool for text annotation, can be accessed through its homepage at http://brat.nlplab.org.\",\n",
        "              \"BRAT is implemented using a web-based architecture, making it accessible through a web browser. It is supported by Natural Language Processing (NLP) technology, which assists in text annotation tasks. The tool allows for rich structured annotation and aims to increase annotator productivity through the use of NLP techniques. The main user interface of BRAT includes features such as annotation editing, which recognizes standard user interface gestures familiar from text editors and presentation software . Annotations in BRAT are created by selecting a span of text with the mouse or double-clicking on a word, and connections between annotations are made by clicking on one annotation and dragging a connection to another . BRAT has been used in the annotation of six different corpora by multiple research groups, resulting in the creation of well-over 50,000 annotations in thousands of documents comprising hundreds of thousands of words\",\n",
        "              \"The experiment showed a 15% decrease in total annotation time as a result of annotation assisted by semantic class disambiguation . This evaluation was conducted on a multicategory entity mention annotation task using pre-release versions of BRAT. The integration of a machine learning-based semantic class disambiguation system, which offered multiple outputs with probability estimates, contributed to reducing ambiguity by an average of over 75% while retaining the correct class in 99% of cases across six corpora. This improvement in annotation efficiency demonstrates the effectiveness of using NLP techniques in supporting manual curation efforts and increasing annotator productivity in text annotation tasks.\"]"
      ],
      "metadata": {
        "id": "s3y-RdvNPJeA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "819JJ3Vdbta1",
        "outputId": "e55e0bb0-83df-49ab-df23-7030997e312f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8603, Recall: 0.9263, F1: 0.8919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy3edMnbbtes",
        "outputId": "f588ee41-39e0-4c15-e64b-bb33dc1de2ea"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8342, Recall: 0.8975, F1: 0.8646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Journal 5**"
      ],
      "metadata": {
        "id": "LBjufU5GPNQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"TextAttack\",\n",
        "              \"https://github.com/QData/TextAttack.\",\n",
        "              \"Proceedings of the 2020 Association for Computational Linguistics.\",\n",
        "              \"Yes, TextAttack is available as a Python package installed from PyPI\",\n",
        "              \"textattack attack\"]"
      ],
      "metadata": {
        "id": "_5noqC-APPae"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The research paper proposes a framework called TextAttack.\",\n",
        "              \"The GitHub link for accessing the code and tutorials of TextAttack is: https://github.com/QData/TextAttack\",\n",
        "              \"This research paper is published in the Proceedings of the Association for Computational Linguistics.\",\n",
        "              \"Yes, TextAttack can be installed as a Python package. It can be installed from PyPI or downloaded directly from GitHub.\",\n",
        "              \"The API command-line from TextAttack that allows users to specify attacks is textattack attack\"]"
      ],
      "metadata": {
        "id": "hIlSV0giPQRe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"Framework proposed in this research paper: The research paper proposes a Python framework called TextAttack for adversarial attacks, data augmentation, and adversarial training in NLP. TextAttack is designed to build attacks using four components: a goal function, a set of constraints, a transformation, and a search method. The modular design of TextAttack allows researchers to easily construct attacks by combining novel and existing components. TextAttack provides implementations of 16 adversarial attacks from the literature and supports various models and datasets, including BERT and other transformers, and all GLUE tasks. In addition to attacks, TextAttack also includes data augmentation and adversarial training modules to improve model accuracy and robustness. The framework aims to democratize NLP by enabling anyone to try data augmentation and adversarial training on any model or dataset with just a few lines of code.\",\n",
        "              \"The code and tutorials for TextAttack can be accessed at the following link: https://github.com/QData/TextAttack\",\n",
        "              \"The research paper TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP does not mention any specific proceedings where it was published. However, it is worth noting that the paper is available on arXiv, an open-access repository for scientific papers. The authors of the paper are John Morris, Eli Lifland, Jin Yoo, Jake Grigsby, Di Jin, and Yanjun Qi. The paper introduces the TextAttack framework, which is a Python framework for adversarial attacks, data augmentation, and adversarial training in NLP. It provides implementations of 16 adversarial attacks from the literature and supports various models and datasets, including BERT and other transformers, and all GLUE tasks. The framework aims to democratize NLP by enabling researchers to easily construct attacks and improve model performance. Code and tutorials for TextAttack can be found on the GitHub repository at https://github.com/QData/TextAttack.\",\n",
        "              \"Yes, TextAttack is available as a Python package that can be installed. The TextAttack framework is designed to be easily accessible and usable by researchers. It provides a modular design that allows users to construct attacks from combinations of novel and existing components. The framework supports a variety of models and datasets, including BERT and other transformers, and all GLUE tasks. To install TextAttack, users can follow the instructions provided in the code repository on GitHub. The code and tutorials for TextAttack can be found at the following link: https://github.com/QData/TextAttack. With just a few lines of code, researchers can try data augmentation and adversarial training on any model or dataset using TextAttack.\",\n",
        "              \"TextAttack provides an API command-line interface that allows users to specify attacks. This command-line interface enables users to easily configure and launch attacks on NLP models. Users can specify the attack type, target model, and dataset, among other parameters, through the command-line interface. The API command-line interface is designed to be user-friendly and accessible, allowing researchers to quickly experiment with different attack configurations. The details of the API command-line interface and its usage can be found in the TextAttack documentation and tutorials provided on the GitHub repository.\"]"
      ],
      "metadata": {
        "id": "R0WkcOClPQWq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc5d1GRebukJ",
        "outputId": "dc1c657f-d48a-445d-d774-10591ca6b0e8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8774, Recall: 0.9200, F1: 0.8982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21x19odKbumm",
        "outputId": "38172f46-4612-4681-e299-57cd79209298"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8081, Recall: 0.8774, F1: 0.8413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**News 1**"
      ],
      "metadata": {
        "id": "8banYczuPQuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"The Korean War ended in 1953\",\n",
        "              \"Kim said inter-Korean relations had become â€œa relationship between two hostile countries and two belligerents at war,â€ the state-run news agency KCNA reported\",\n",
        "              \"January 1, 2024\",\n",
        "              \"Hoo Chiew-Ping\",\n",
        "              \"three\"]"
      ],
      "metadata": {
        "id": "v7SXO4jEPUPP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The Korean War ended in 1953 with an armistice.\",\n",
        "              \"Based on the news agency KCNA report, Kim Jong Un stated that North Korea will no longer engage in inter-Korean relations. He mentioned that future South Korean administrations extending an olive branch will be vehemently rejected by North Korea. Kim's statement suggests a departure from any potential reconciliation or reunification efforts between North and South Korea.\",\n",
        "              \"The news article was published on Monday, January 1, 2024.\",\n",
        "              \"Hoo Chiew-Ping, a senior fellow at the East Asian International Relations CAUCUS (EAIR) and member of the Asia Pacific Nuclear Advisory Panel (APNAP), said that the North Korean leader has been increasingly walking away from inter-Korean relations in recent years.\",\n",
        "              \"North Korea plans to add three additional spy satellites by 2024.\"]"
      ],
      "metadata": {
        "id": "1O5rSnSYPUxY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"The Korean War ended on July 27, 1953.\",\n",
        "              \"Kim made statements about inter-Korean relations based on news agency KCNA reports. The specific details of what Kim said about inter-Korean relations are not provided in the given abstracts and contexts.\",\n",
        "              \"The specific time of the news publication is not mentioned in the provided abstracts and contexts. The information about the time of news publication is not available in the given sources.\",\n",
        "              \"The person who stated that the North Korean leader has been increasingly walking away from inter-Korean relations in recent years is not mentioned in the provided abstracts and contexts. The specific individual who made this statement is not identified in the given sources. The abstracts and contexts do not provide information about the person who made the observation about the North Korean leader's distancing from inter-Korean relations. Unfortunately, the sources do not mention the name of the person who made the statement about the North Korean leader's decreasing involvement in inter-Korean relations.\",\n",
        "              \"The abstracts and contexts provided do not mention any specific information about North Korea's plans to add spy satellites by 2024. There is no mention of the number of spy satellites that North Korea plans to add by 2024 in the given sources. The sources do not provide any details regarding North Korea's future plans for the addition of spy satellites. Unfortunately, the abstracts and contexts do not contain any information about North Korea's intended number of spy satellites by 2024. The specific number of spy satellites that North Korea plans to add by 2024 is not mentioned in the provided sources.\"]"
      ],
      "metadata": {
        "id": "PJDEHpk-PU0h"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJfsGsnLbvix",
        "outputId": "dcb40954-02a1-4a35-a55a-d0e6d9b13ac4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8163, Recall: 0.8952, F1: 0.8527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zjmaxQ7bvlZ",
        "outputId": "6b0cfbc0-bee9-4ad4-941e-71272f8bf1c6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8251, Recall: 0.8385, F1: 0.8312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**News 2**"
      ],
      "metadata": {
        "id": "m6bU_tUZPZuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"The waiting migrants feel desperate\",\n",
        "              \"9,600 migrant encounters\",\n",
        "              \"1,000 migrants arrived\",\n",
        "              \"3,800 in Tijuana, 3,273 in Reynosa, and 4,000 in Matamoros\",\n",
        "              \"445,000\"]"
      ],
      "metadata": {
        "id": "2Ukt_N9wPbcE"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"According to CaÃ±as, the waiting migrants feel desperate\",\n",
        "              \"According to the report, Federal authorities reported a seven-day average of more than 9,600 migrant encounters along the US southern border in December.\",\n",
        "              \"According to the director of a migrant shelter in Piedras Negras, about 1,000 migrants arrived by train on Monday.\",\n",
        "              \"In Tijuana, an estimated 3,800 migrants are staying in shelters. In Reynosa, there are 3,273 migrants staying in shelters. The number of migrants staying in shelters in Matamoros is not mentioned in the provided context.\",\n",
        "              \"The US Department of Homeland Security has deported or returned over 445,000 migrants since May, according to the agency's online statement.\"]"
      ],
      "metadata": {
        "id": "k2PS2VnGPwW2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"The provided abstracts and contexts do not mention any information about CaÃ±as or their perspective on the feelings of waiting migrants. There is no reference to CaÃ±as or their insights on the emotions experienced by waiting migrants in the given sources. Unfortunately, the sources do not provide any details about CaÃ±as' observations or opinions regarding the feelings of waiting migrants. CaÃ±as' perspective on the emotions felt by waiting migrants is not mentioned in the provided abstracts and contexts. The abstracts and contexts do not contain any information about CaÃ±as' views on the experiences of waiting migrants.\",\n",
        "              \"In December, Federal authorities reported a seven-day average of more than 9,600 migrant encounters along the US southern border. This number represents a significant increase compared to the seven-day average reported on November 28, which was about 6,800 encounters. The surge of people crossing into the US from Mexico has put a strain on US border cities in recent weeks. The increase in migrant encounters highlights the ongoing challenge faced by US Customs and Border Protection (CBP) in addressing the border surge. Despite efforts to address the situation, illegal crossings continue to occur, particularly in rural areas of Arizona, fueled by bad actors pushing migrants to enter between ports of entry. The situation at the border has prompted discussions between Mexican President Andres Manuel Lopez Obrador and US officials, including Secretary of State Antony Blinken and Secretary of Homeland Security Alejandro Mayorkas. \",\n",
        "              \"The director of a migrant shelter in Piedras Negras, Mexico, reported that about 1,000 migrants arrived by train on Monday. The shelter director's statement highlights the continued arrival of large groups of migrants at the border by train. The influx of migrants has led to temporary halts in crossing due to violence in the streets of Piedras Negras. The arrival of migrants by train adds to the challenges faced by US Customs and Border Protection in managing the border surge. The situation at the border has prompted discussions between Mexican President Andres Manuel Lopez Obrador and US officials, including Secretary of State Antony Blinken and Secretary of Homeland Security Alejandro Mayorkas. The meeting between Mexican and US officials aims to address the ongoing border situation and immigration policy.\",\n",
        "              \"In Tijuana, Mexico, an estimated 3,800 migrants from countries like Mexico, Cuba, Haiti, and Venezuela are staying in shelters. In Reynosa, Mexico, another 3,273 migrants are waiting at Senda De Vida shelters. In nearby Matamoros, Mexico, about 4,000 migrants are living in camps, shelters, and abandoned homes. The total number of migrants staying in shelters in Tijuana, Reynosa, and Matamoros is approximately 11,073. These migrants are waiting on the Mexican side of the border, hoping to enter the US through legal pathways established by the Biden administration. The situation at the border has prompted discussions between Mexican President Andres Manuel Lopez Obrador and US officials, including Secretary of State Antony Blinken and Secretary of Homeland Security Alejandro Mayorkas.\",\n",
        "              \"The US Department of Homeland Security has deported or returned over 445,000 migrants since May, according to the agency's online statement. The majority of these migrants had crossed the US Southern border. The deportation and return of migrants is part of the government's efforts to address the ongoing border surge and maximize limited resources. The federal government has also closed ports of entry in multiple states and reassigned personnel to transport and process migrants. The Biden Administration temporarily suspended rail operations in Eagle Pass and El Paso, but those services have since resumed. Despite these measures, illegal crossings continue to occur, particularly in rural areas of Arizona, where bad actors are pushing migrants to enter the US southern border between ports of entry.\"]"
      ],
      "metadata": {
        "id": "A818fDV6PwZg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2aC-sTRbwaE",
        "outputId": "b02f9d91-67fb-4c92-f0b8-fa6e50bbb3ed"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8515, Recall: 0.9173, F1: 0.8831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rubPpNMBbwcn",
        "outputId": "45895793-25fc-4bfe-be6e-0f44b56ef476"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.7880, Recall: 0.8806, F1: 0.8316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**News 3**"
      ],
      "metadata": {
        "id": "tKxEHwBvPwo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"active Pacific storm track typical of an El NiÃ±o winter will send a series of storms across the US into next week\",\n",
        "              \"Thursday evening\",\n",
        "              \"Heavy precipitation will spread across the Southeast/Mid-Atlantic and possibly the Northeast this coming weekend, with increasing potential for heavy snow to the north and west of the low\",\n",
        "              \"Northeast and mid-Atlantic\",\n",
        "              \"2.3 inches fell during the entirety of 2023\"]"
      ],
      "metadata": {
        "id": "qB28e-COPzE-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The highest chance for impactful snow on the East Coast this winter is caused by an active Pacific storm track that is typical of an El NiÃ±o winter. This storm track is sending a series of storms across the US, presenting the highest chance for impactful snow so far this winter in some of the country's most populous areas on the East Coast.\",\n",
        "              \"Rain will begin Thursday evening in eastern Texas.\",\n",
        "              \"The Weather Prediction Center stated that heavy precipitation will spread across the Southeast/Mid-Atlantic and possibly the Northeast, with increasing potential for heavy snow to the north and west of the low. They also mentioned that the exact amounts and precipitation type for some major East Coast cities remain highly uncertain but need to be watched.\",\n",
        "              \"Winter may finally arrive in the Northeast and mid-Atlantic in the form of a storm.\",\n",
        "              \"According to the National Weather Service, only 2.3 inches of snow fell in Central Park during the entirety of 2023, making it the least snowy calendar year on record for New York City.\"]"
      ],
      "metadata": {
        "id": "IMLl8tfZPzio"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"The highest chance for impactful snow this winter on the East Coast was caused by an active Pacific storm track typical of an El Nino winter, which sent a series of storms across the US. These storms crossed the southern half of the US before moving up the East Coast, presenting the highest chance for impactful snow in some of the country's most populous areas. The storm system brought heavy precipitation, and the key question was where it would fall as snow and where it would fall as rain, especially along the highly populated I-95 corridor from Washington, DC, to Boston. If even an inch of snow were to fall in this corridor, it would end significant snowless streaks for major cities that have lasted for nearly two years. The storm system was expected to bring significant snow to higher elevation areas of the Appalachians and the interior Northeast, including central Pennsylvania.\",\n",
        "              \"Rain is predicted to begin in eastern Texas on Thursday evening, according to the provided context. The rain is expected to progress with the storm's track to the east, overrunning the Southeast and parts of the mid-Atlantic with time. This storm system could cause flooding issues in the South, particularly in areas that have already experienced heavy rainfall earlier in the week. The exact track of the storm becomes less certain after it leaves the Southeast, but heavy precipitation is expected to spread across the Southeast, Mid-Atlantic, and possibly the Northeast over the coming weekend. The forecast models differ on the amount of snow that could fall and where, but there is increasing potential for heavy snow to the north and west of the low-pressure system. The storm system is part of an active Pacific storm track typical of an El Nino winter, which is bringing a series of storms across the US and presenting the highest chance for impactful snow on the East Coast this winter. \",\n",
        "              \"The Weather Prediction Center stated that heavy precipitation will spread across the Southeast, Mid-Atlantic, and possibly the Northeast over the coming weekend, with increasing potential for heavy snow to the north and west of the low-pressure system. The exact amounts and precipitation type for major East Coast cities remain highly uncertain at this point, but it is advised to monitor the situation closely. The forecast models differ on the amount of snow that could fall and where, but there is a high confidence for significant snow in higher elevation areas of the Appalachians and the interior Northeast, including central Pennsylvania. The key question is where the precipitation will fall as snow and where it will fall as rain, especially along the highly populated I-95 corridor from Washington, DC, to Boston. Even an inch of snow in this corridor would end significant snowless streaks for major cities that have lasted for nearly two years. New York City, Philadelphia, and the DC area's Dulles International Airport experienced their least snowy calendar year on record in 2023, with only 2.3 inches of snow falling in Central Park.\",\n",
        "              \"Winter may finally arrive in the Northeast and mid-Atlantic in the form of a weekend storm, bringing the potential for decent snow after nearly two years of snowless streaks. The storm's timing, intensity, and track are still uncertain, as the system responsible for it is still thousands of miles away off the West Coast of the US. The highest confidence for significant snow is in higher elevation areas of the Appalachians and the interior Northeast, including central Pennsylvania. The key question is where the precipitation will fall as snow and where it will fall as rain, especially along the highly populated I-95 corridor from Washington, DC, to Boston. Major cities like New York City, Philadelphia, and the DC area's Dulles International Airport have experienced significant snowless streaks, with New York City waiting nearly 700 days for an inch of snow in a single calendar day.\",\n",
        "              \"According to the National Weather Service, Central Park in New York City experienced its least snowy calendar year on record in 2023, with only 2.3 inches of snow falling during the entirety of the year. New York City has been waiting nearly 700 days for an inch of snow in a single calendar day. The forecast models for the upcoming weekend storm differ on the amount of snow that could fall in Central Park, but the exact amounts and precipitation type for major East Coast cities remain highly uncertain at this point. It is advised to monitor the situation closely as the storm's timing, intensity, and track are still uncertain, given that the system responsible for it is still thousands of miles away off the West Coast of the US.\"]"
      ],
      "metadata": {
        "id": "_qYXelCYPzn1"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xU2H1RqDbxjD",
        "outputId": "f66f49ce-5894-4448-87e1-6332745d498b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8727, Recall: 0.9299, F1: 0.9004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXXGpnqObxlh",
        "outputId": "25b94010-0711-471b-8c3a-6848e9f1223a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8122, Recall: 0.9136, F1: 0.8599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**News 4**"
      ],
      "metadata": {
        "id": "tVHVrZCiPzxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"stabbed in the neck\",\n",
        "              \"Lee was touring the construction site of the Gadeokdo New Airport and talking to reporters when he was attacked\",\n",
        "              \"Lee suffered â€œsuspected damage to his jugular veinâ€ and doctors were concerned he may have additional bleeding\",\n",
        "              \"Lee Jae-myung\",\n",
        "              \"18 cm or 7 inch\"]"
      ],
      "metadata": {
        "id": "muJRYUHrP1Ed"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"South Korea's main opposition party leader, Lee Jae-myung, was stabbed in the neck.\",\n",
        "              \"Lee Jae-myung was attacked during a visit to the southern city of Busan. He was attacked while touring the construction site of the Gadeokdo New Airport and talking to reporters.\",\n",
        "              \"The doctors mentioned that Lee underwent vein reconstruction surgery and is currently recovering in the intensive care unit. They also expressed concerns about potential additional bleeding and suspected damage to his jugular vein.\",\n",
        "              \"The person being stabbed is Lee Jae-myung, the main opposition party leader in South Korea.\",\n",
        "              \"The knife used by the assailant to stab Lee was 18 cm (7 inches) long.\"]"
      ],
      "metadata": {
        "id": "NQPiMn7iP1cx"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"South Korea's main opposition party leader, Lee Jae-myung, was stabbed in the neck.\",\n",
        "              \"Lee Jae-myung was attacked in the southern city of Busan. He was attacked while touring the construction site of the Gadeokdo New Airport\",\n",
        "              \"Doctors stated that Lee Jae-myung suffered a 1-centimeter laceration on the left side of his neck. They were concerned about possible damage to his jugular vein and the potential for additional bleeding. Lee underwent vein reconstruction surgery and is currently recovering in the intensive care unit \",\n",
        "              \"Lee Jae-myung, the leader of South Korea's main opposition party, was stabbed in the neck\",\n",
        "              \"The knife used by the assailant to stab Lee Jae-myung was 18 cm (7 inches) long.\"]"
      ],
      "metadata": {
        "id": "POvGdblYP1fd"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndVJKcZhbyg_",
        "outputId": "786575d1-47de-4390-9d1e-be4362d04958"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8636, Recall: 0.9135, F1: 0.8877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz6HZGZwbyjc",
        "outputId": "e94c55e1-8d80-4686-e415-315a9991d93a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8581, Recall: 0.9229, F1: 0.8891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**News 5**"
      ],
      "metadata": {
        "id": "A64vOr7tP1mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"Japan Airlines said four of its passengers were taken to hospitals but the airline has not received any additional reports of injuries\",\n",
        "              \"Japan Airlines,  and The French aviation agency\",\n",
        "              \" Japan Coast Guard aircraft\",\n",
        "              \"five dead, 379 evacuated\",\n",
        "              \"Airbus A350-900 aircraft\"]"
      ],
      "metadata": {
        "id": "jQzZ7SfrP2xt"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The airlineâ€™s Senior Vice President Noriyuki Aoki said in a press conference Tuesday evening that four of Japan Airlines' passengers were taken to hospitals, but they have not received any additional reports of injuries.\",\n",
        "              \"Japan Airlines and the French aviation agency both participated in the investigation to determine who was responsible for the plane crash.\",\n",
        "              \"The Japan Air Lines Airbus A350 collided with a De Havilland Canada DHC-8, which was operated by the Japan Coast Guard, before catching fire.\",\n",
        "              \"Five people were killed in the incident. All 379 people on JAL flight 516 were safely evacuated from the passenger plane.\",\n",
        "              \"The airplane that caught fire after taking off from Sapporo city was an Airbus A350-900 aircraft.\"]"
      ],
      "metadata": {
        "id": "X0ZvFaZ7P3LQ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"The provided sources do not mention any press conference held by the airline's Senior Vice President Noriyuki Aoki on Tuesday evening. Therefore, it is not possible to provide any information about what he said in the press conference.\",\n",
        "              \"Participants in the investigation to determine responsibility for the plane crash: Japan Airlines: The airline is taking part in the investigation to determine responsibility for the crash. Senior Vice President of Corporate Safety and Security Tadayuki Tsutsumi: He stated that Japan Airlines is participating in the investigation. France's aviation agency: The agency is sending its own investigators to Tokyo to probe the collision as part of the investigation team opened by the Japan Transport Safety Board. Japan Transport Safety Board: They have opened an investigation team to determine responsibility for the crash. Note: The sources do not provide information about any other specific individuals or organizations participating in the investigation.\",\n",
        "              \"The Japan Air Lines Airbus A350 caught fire after colliding with a De Havilland Canada DHC-8 aircraft. Note: The provided sources do not mention any other specific details about the type of plane involved in the collision.\",\n",
        "              \"Five people were killed in the JAL flight 516 incident at Tokyo's Haneda airport. All 379 people on board JAL flight 516, including eight children under the age of two, were safely evacuated from the passenger plane. Note: The provided sources do not provide any additional information regarding the number of people who were injured in the incident.\",\n",
        "              \"The airplane that ignited after flying out of Sapporo city was an Airbus A350-900 aircraft. Note: The provided sources do not mention any other specific details about the type of airplane involved in the incident.\"]"
      ],
      "metadata": {
        "id": "PIIHxy-XP3Oa"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf8ID_NPbzr5",
        "outputId": "d49e73e2-3696-47f1-9ef5-1eb6c899903a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8569, Recall: 0.9186, F1: 0.8866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7yVV4ulbz6P",
        "outputId": "e79b15c0-8d70-4a0c-e050-8072acf254be"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8134, Recall: 0.8729, F1: 0.8418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Report 1**"
      ],
      "metadata": {
        "id": "C3P7TVzfP3YU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"Inflation slowed to a 3.1% annual rate in November\",\n",
        "              \"December 12, 2023\",\n",
        "              \"gasoline fell 6% and fuel oil was off 2.7%\",\n",
        "              \"2.3%\",\n",
        "              \"0.1%\"]"
      ],
      "metadata": {
        "id": "IU-_EylYP6C8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The title of the news report is Inflation showed to a 3.1% annual rate in November\",\n",
        "              \"The news report was published on Tuesday, December 12, 2023\",\n",
        "              \"The price of gasoline has decreased by 6% and the price of fuel oil has decreased by 2.7%.\",\n",
        "              \"The decrease in energy prices helped keep inflation in check by reducing the overall cost of energy-related goods and services. Specifically, gasoline prices fell by 6% and fuel oil prices were down by 2.7%. This decline in energy prices contributed to lower overall inflation as it offset some of the price increases in other categories.\",\n",
        "              \"The consumer price index increased by 0.1% in November.\"]"
      ],
      "metadata": {
        "id": "ndhFqL7DP8Uj"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"Title of the news report: Inflation slowed to a 3.1% annual rate in November\",\n",
        "              \"The provided sources do not mention the specific date of when the news report was published.\",\n",
        "              \"Gasoline and Fuel Oil Price Decrease: Gasoline prices fell by 6% in November, contributing to a decrease in energy prices. Fuel oil prices were down by 2.7% in November, further contributing to the decrease in energy prices. Note: The provided sources do not mention the percentage decrease in gasoline and fuel oil prices on an annual basis.\",\n",
        "              \"Decrease in Energy Prices and Inflation: The decrease in energy prices, specifically a 2.3% decrease, helped keep inflation in check. This was primarily driven by a 6% decrease in gasoline prices and a 2.7% decrease in fuel oil prices. The decline in energy prices contributed to overall inflation remaining relatively low. It helped offset any potential upward pressure on prices that could have resulted from other factors. The decrease in energy prices played a significant role in keeping inflation in check, as energy costs are a major component of overall consumer prices. The impact of the decrease in energy prices on inflation was evident in the consumer price index, which increased by only 0.1% in November. The decline in energy prices also contributed to the core consumer price index, which excludes volatile food and energy prices, increasing by 0.3% on the month. Overall, the decrease in energy prices helped to mitigate inflationary pressures and contributed to the stability of consumer prices.\",\n",
        "              \"Consumer Price Index Increase in November: The consumer price index (CPI) increased by 0.1% in November, according to the provided sources. This indicates a slight uptick in consumer prices during that month. The CPI measures the average change over time in the prices paid by urban consumers for a market basket of consumer goods and services. The 0.1% increase in the CPI suggests a modest rise in overall consumer prices. It is important to note that this increase is specific to the month of November and does not provide information about long-term trends in inflation. For a more comprehensive understanding of inflation, policymakers often focus on core inflation, which excludes volatile food and energy prices. The core CPI increased by 0.3% on the month, indicating a slightly higher rate of inflation when excluding these volatile components.\"]"
      ],
      "metadata": {
        "id": "M9aa9dLCP8XL"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xKqNyyEb1Bf",
        "outputId": "ca859709-5082-448d-f3bc-33adcca3bfaa"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8421, Recall: 0.9058, F1: 0.8725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usJy999sb1D4",
        "outputId": "6144ce92-d11d-452e-8356-275fae73d1e7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8260, Recall: 0.8831, F1: 0.8529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Report 2**"
      ],
      "metadata": {
        "id": "BrubEvOLP8eL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"Nvidia to launch slower version of its gaming chip in China to comply with U.S. export controls\",\n",
        "              \"December 29, 2023\",\n",
        "              \"11%\",\n",
        "              \"Yes, Nvidia RTX 4090 was included on the list of banned U.S made chips\",\n",
        "              \" rush of demand for AI, OpenAIâ€™s ChatGPT chatbot.\"]"
      ],
      "metadata": {
        "id": "6rvj030BP9i7"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The title of the news report is Nvidia to launch slower version of its gaming chip in China to comply with U.S. export controls\",\n",
        "              \"The news report titled Nvidia to launch slower version of its gaming chip in China to comply with U.S. export controls was published on Friday, December 29, 2023.\",\n",
        "              \"The Nvidia RTX 4090D for Chinese consumers has 11% fewer CUDA cores than versions sold outside of China.\",\n",
        "              \"Based on the information provided, the Nvidia RTX 4090 is not explicitly mentioned as being banned in the US in the Securities and Exchange Commission filing.\",\n",
        "              \"The company, Nvidia, benefits the most from the demand in the artificial intelligence (AI) sector of the market. The rush of demand for AI, including the buzz caused by OpenAI's ChatGPT chatbot, has contributed to the significant increase in Nvidia's stock price. Additionally, the export restrictions imposed by the U.S. on China primarily target chips that enable AI applications, which indicates the importance of the AI sector for Nvidia's business.\"]"
      ],
      "metadata": {
        "id": "4e1J86Q4P9y1"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"Title: Nvidia to launch slower version of its gaming chip in China to comply with U.S. export controls.\",\n",
        "              \"The news about Nvidia launching a slower version of its gaming chip in China to comply with U.S. export controls was published on an unspecified date.\",\n",
        "              \"The percentage difference in CUDA cores on the Nvidia RTX 4090D for Chinese and non-Chinese consumers is 11 fewer cores for the Chinese version\",\n",
        "              \"No, the Nvidia RTX 4090 is not explicitly mentioned as being banned in the US based on the Securities and Exchange Commission (SEC) filing. However, the export rules mentioned in the filing primarily target chips that enable AI applications, and gaming-focused processors like the Nvidia RTX 4090 are also affected as they have potential uses in artificial intelligence. Nvidia has taken steps to comply with US government export controls by launching a slower version of the chip, the Nvidia RTX 4090D, in China. The Chinese version of the chip has 11 fewer CUDA cores compared to versions sold outside of China. This modification is likely designed to ensure compliance with US export controls.\",\n",
        "              \"Nvidia benefits the most from the gaming sector of the market demand. Nvidia's RTX line of advanced gaming GPUs, including the Nvidia RTX 4090D, is designed for gaming applications. The company's CUDA architecture, which is equivalent to CPU cores, is primarily used for gaming graphics processing units (GPUs). While the export restrictions imposed by the US primarily target chips enabling AI applications, gaming-focused processors like Nvidia's RTX chips are also affected as they have potential uses in artificial intelligence. Nvidia has developed the Nvidia RTX 4090D, a slower version of its gaming chip, specifically for the Chinese market to comply with US export controls. The modification in the Chinese version of the chip includes 11 fewer CUDA cores compared to versions sold outside of China. Overall, Nvidia's gaming-focused processors, such as the Nvidia RTX 4090D, cater to the demands of the gaming sector in the market.\"]"
      ],
      "metadata": {
        "id": "xldnpe1lP91N"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kGlpQh4b2Am",
        "outputId": "79a7266b-a2b3-4f65-c543-9a55a6e5ac18"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8504, Recall: 0.9036, F1: 0.8761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlq2mdb6b2DF",
        "outputId": "7d003738-4334-4b35-c1c8-1b7f0f3bcce6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8426, Recall: 0.8673, F1: 0.8543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Report 3**"
      ],
      "metadata": {
        "id": "NnbLg40bP-H8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"Unemployment among Asian workers and Black men rises in November while the overall rate declines\",\n",
        "              \"December 8, 2023\",\n",
        "              \"LISA KAILAI HAN\",\n",
        "              \"0.2% \",\n",
        "              \"That uptick in unemployment is not because more Asian workers are flooding into the labor market, feeling optimistic about getting jobs. Itâ€™s actually accompanied by a fall in participation as well as a fall in employment\"]"
      ],
      "metadata": {
        "id": "XOF2FrAIP_Us"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The main topic of the news report is the unemployment rates among different demographic groups in the U.S., specifically focusing on the rise in unemployment among Asian workers and Black men in November, while the overall unemployment rate declined.\",\n",
        "              \"The news was published on Friday, December 8, 2023.\",\n",
        "              \"The writer of the news is Lisa Kailai Han.\",\n",
        "              \"The unemployment rate declined by 0.2% last month.\",\n",
        "              \"Elise Gould stated, That uptick in unemployment is not because more Asian workers are flooding into the labor market, feeling optimistic about getting jobs. Itâ€™s actually accompanied by a fall in participation as well as a fall in employment.\"]"
      ],
      "metadata": {
        "id": "LvsS_gaFP_1s"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"Main Topic of the News Report: Unemployment Rates among Asian Workers and Black Men in November. The overall unemployment rate declined to 3.7% in November, against a forecast of 3.9%. Asian Americans saw a 0.4 percentage-point jump in the unemployment rate to 3.5%. The unemployment rate for Black Americans held steady at 5.8%, which is the demographic with the highest jobless percentage in the U.S. The increase in unemployment among Asian workers is accompanied by a fall in participation and employment. Black Americans were hit harder by business shutdowns during the Covid-19 pandemic, with a peak unemployment rate of 16.8% in 2020. The labor market deteriorated for both Asian and Black workers in November. The overall unemployment rate declined to 3.7% in November, and the labor force participation rate ticked up to 62.8% with a surge of 532,000 workers entering the labor force.\",\n",
        "              \"The provided sources do not mention the specific date of when the news was published.\",\n",
        "              \"The news report does not provide information about the specific author or authors of the report.\",\n",
        "              \"The overall unemployment rate declined by 0.2% last month.\",\n",
        "              \"Elise Gould, senior economist at the Economic Policy Institute, told CNBC that the uptick in unemployment among Asian workers and Black men is not due to more workers entering the labor market with optimism about finding jobs. She mentioned that the increase in unemployment is accompanied by a fall in participation as well as a fall in employment. She also highlighted that the unemployment rate for Black Americans, the demographic with the highest jobless percentage in the U.S., held steady at 5.8%. Additionally, she noted that the unemployment rate for Black men age 20 or older spiked to 6.4% from October's 5.3%, while the participation rate for this cohort increased to 69.2% from 67.5%.\"]"
      ],
      "metadata": {
        "id": "KvZN2yfxP_4L"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJmXiMZ3b3RB",
        "outputId": "7ff838a0-63f6-450e-bac7-2ca2a7127b76"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8710, Recall: 0.9144, F1: 0.8920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWrQ_lUzb3Tw",
        "outputId": "e938eeb3-48dc-4a80-94f4-063af6eb8da0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8158, Recall: 0.8544, F1: 0.8338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Report 4**"
      ],
      "metadata": {
        "id": "QMSey_uHP_-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"Tesla reported delivery and production numbers for the fourth quarter\",\n",
        "              \"January 2, 2024\",\n",
        "              \"Total deliveries Q4 2023 is 484.507,  Total production Q4 2023 is 494.989, Total annual deliveries 2023 is 1.808.581, Total annual production 2023 is 1.845.985\",\n",
        "              \"1.31 million deliveries, and 1.37 million production\",\n",
        "              \"3.02 million\"]"
      ],
      "metadata": {
        "id": "QJBozETvQBPW"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The main topic of the news is Tesla's delivery and production numbers, as well as their plans for future growth and their competition in the electric vehicle market.\",\n",
        "              \"The news report was published on Tuesday, January 2, 2024.\",\n",
        "              \"The key numbers from Tesla's fourth-quarter vehicle production and deliveries report for 2023 are as follows: Total deliveries Q4 2023: 484,507 Total production Q4 2023: 494,989 Total annual deliveries 2023: 1,808,581 Total annual production 2023: 1,845,985\",\n",
        "              \"In 2022, Tesla reported annual deliveries of 1.31 million electric vehicles and production of 1.37 million electric vehicles.\",\n",
        "              \"BYD sold 3.02 million new energy vehicles in 2023.\"]"
      ],
      "metadata": {
        "id": "FcCMMnZMQBvS"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"Main Topic of the News: Tesla's Fourth Quarter Deliveries and Total Deliveries for 2023. Tesla reported 485,000 deliveries for the fourth quarter of 2023, bringing the total deliveries for the year to 1.8 million. The company's CEO, Elon Musk, had previously stated that the Model Y would likely be the bestselling car in terms of unit volume for the year. Tesla implemented a strategy of slashing prices in the last quarter of 2023 to cope with economic uncertainty and shifting consumer sentiment. Tesla's biggest competitor, Chinese automaker BYD, sold 3.02 million new energy vehicles in 2023. Tesla began advertising campaigns in the second half of 2023, a departure from its previous nontraditional marketing efforts. Analysts had expected Tesla to report deliveries of 477,000 for the year-ending quarter.\",\n",
        "              \"Publication Date of the News: January 2, 2024\",\n",
        "              \"Key Numbers of Tesla's Fourth-Quarter Vehicle Production and Deliveries Report for 2023: Tesla reported 485,000 deliveries for the fourth quarter of 2023, bringing the total deliveries for the year to 1.8 million. Tesla produced 476,777 Model 3 and Model Y vehicles during the quarter and reported 461,538 deliveries for these models. The company did not provide specific production or delivery numbers for the Model S or Model X, instead categorizing them as Other Models. It produced 18,212 other models and delivered 22,969 during the quarter. Note: The sources do not provide a breakdown of delivery and production numbers by individual model, so the specific numbers for the Model Y, Model S, and Model X are not available.\",\n",
        "              \"Tesla's report for 2022 does not exist in the provided sources.\",\n",
        "              \"Chinese automaker BYD sold 3.02 million new energy vehicles in 2023. Of these, 1.6 million were battery-electric passenger cars, and 1.4 million were hybrid electric models. BYD's sales figures indicate a significant presence in the new energy vehicle market, highlighting the company's commitment to sustainable transportation solutions\"]"
      ],
      "metadata": {
        "id": "v-1X1tNIQBx9"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y8HJk6Vb4NQ",
        "outputId": "be0a88e8-b9e2-429e-ad38-bb0776ae0136"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8477, Recall: 0.9055, F1: 0.8754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Nii13Nvb4Ps",
        "outputId": "68cfd03e-a13b-4ec0-e11d-9a1e67413e05"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8227, Recall: 0.8748, F1: 0.8478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Report 5**"
      ],
      "metadata": {
        "id": "xF-aBpLIQB6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"Copper could skyrocket over 75% to record highs by 2025 â€” brace for deficits, analysts say\",\n",
        "              \"January 2, 2024\",\n",
        "              \"LEE YING SHAN\",\n",
        "              \"$8,559 a ton\",\n",
        "              \"Rising demand driven by the green energy transition and a likely decline in the U.S. dollar in the second half of 2024\"]"
      ],
      "metadata": {
        "id": "l_6Ckl18QDoi"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The title of the news report is Copper could skyrocket over 75% to record highs by 2025 â€” brace for deficits, analysts say.\",\n",
        "              \"The news report was published on Tuesday, January 2, 2024.\",\n",
        "              \"The writer who published the news report is Lee Ying Shan.\",\n",
        "              \"The last price of copper on the London Metal Exchange was $8,559 per ton.\",\n",
        "              \"According to the report by BMI, the rise in copper prices is attributed to two main factors: mining supply disruptions and higher demand for the metal. The disruptions in mining supply and the increasing demand are both fueled by the push for renewable energy. Additionally, the likely decline in the U.S. dollar in the second half of 2024 is also expected to contribute to the increase in copper prices.\"]"
      ],
      "metadata": {
        "id": "5g6J2VuSQEG3"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"Title of the news report: Copper could skyrocket over 75% to record highs by 2025 - brace for deficits, analysts say Copper is headed for a price spurt over the next two years, as mining supply disruptions coincide with higher demand for the metal. Copper prices on the London Metal Exchange last saw an all-time record high of 10,730 per ton in March last year.\",\n",
        "              \"The news report does not provide the specific date of publication.\",\n",
        "              \"The information provided does not mention the name of the writer or author who published the news report.\",\n",
        "              \"The last price of copper on the London Metal Exchange was 8,559 per ton\",\n",
        "              \"According to a report by BMI, a Fitch Solutions research unit, the following factors caused copper prices to rise: Mining supply disruptions: The report highlights that mining supply disruptions have contributed to the increase in copper prices. Higher demand driven by the green energy transition: The push for renewable energy has led to a rise in demand for copper, as it is a key component in renewable energy infrastructure. The report suggests that this increased demand has played a significant role in driving up copper prices. Decline in the U.S. dollar strength: The report predicts a likely decline in the strength of the U.S. dollar in the second half of 2024. A weaker U.S. dollar makes copper, priced in greenbacks, more attractive to foreign buyers, further supporting the increase in copper prices. The report also mentions that the positive view for copper is more influenced by macro factors such as potential Fed rate cuts and a weaker U.S. dollar.\"]"
      ],
      "metadata": {
        "id": "y8wan8ITQEJm"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7B4MSmMb5Jc",
        "outputId": "494a80d6-72ae-4827-bd83-dd227fb6d343"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8411, Recall: 0.8979, F1: 0.8684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49GbrCoqb5MB",
        "outputId": "df199126-ec5f-43a3-fe15-c4a97685f5d6"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8096, Recall: 0.8513, F1: 0.8292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tutorial 1**"
      ],
      "metadata": {
        "id": "wtLRj1ndQEbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"BOURBON CHICKEN\",\n",
        "              \"LinMarie\",\n",
        "              \"2 lbs\",\n",
        "              \"yes\",\n",
        "              \"1/2 cup\"]"
      ],
      "metadata": {
        "id": "-SaeTUWPQIlq"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The recipe will result in Bourbon Chicken, a dish made with bite-sized pieces of chicken cooked in a flavorful sauce made with ingredients like garlic, ginger, crushed red pepper flakes, apple juice, brown sugar, ketchup, cider vinegar, water, and soy sauce. It is typically served over hot rice.\",\n",
        "              \"The recipe for Bourbon Chicken was submitted by LinMarie.\",\n",
        "              \"The recipe calls for 2 lbs of boneless chicken breasts, but it does not specify the exact number of chicken breasts needed. The number of chicken breasts required will depend on the size of the individual chicken breasts.\",\n",
        "              \"Yes, olive oil is required for this recipe. It is used to heat in a large skillet before adding the chicken pieces.\",\n",
        "              \"The recipe calls for 1/2 cup of water.\"]"
      ],
      "metadata": {
        "id": "Oz_yJwchQV9D"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"Food Type: Chicken dish. The recipe calls for boneless chicken breasts, which are cut into bite-size pieces and cooked with olive oil.\",\n",
        "              \"There is no information available in the provided sources about who submitted the recipe.\",\n",
        "              \"Number of chicken breasts needed: The recipe calls for 2 lbs of boneless chicken breasts, cut into bite-size pieces.\",\n",
        "              \"Yes, the recipe calls for 1-2 tablespoons of olive oil to be used in cooking the chicken breasts.\",\n",
        "              \"The provided sources do not mention the amount of water needed in the recipe. Therefore, we cannot determine the exact amount of water required based on the given information. Please note that the sources provided do not mention the specific details about the amount of water needed in the recipe. It is possible that the recipe does not require water or that the amount of water needed is not mentioned in the sources provided. To find the exact amount of water needed, it would be helpful to refer to other sources or recipe variations that provide this information.\"]"
      ],
      "metadata": {
        "id": "mkRVkMkfQWA0"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9ttQcL2b6QA",
        "outputId": "b2711cb2-c047-4fff-cd67-deb7e11416d0"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8059, Recall: 0.8463, F1: 0.8255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPXqckPxb6Sl",
        "outputId": "5581d784-7e86-4e6f-a50e-e2cf3a0e06d5"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.7931, Recall: 0.8024, F1: 0.7972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tutorial 2**"
      ],
      "metadata": {
        "id": "YEuzoOGwQWcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"PANCAKES\",\n",
        "              \"Ellen Brody\",\n",
        "              \"1 teaspoon\",\n",
        "              \"Beat the egg until fluffy\",\n",
        "              \"When bubbles appear on surface and begin to break\"]"
      ],
      "metadata": {
        "id": "WYm0VoDoQYV3"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The recipe is for making pancakes.\",\n",
        "              \"The recipe was submitted by Ellen Brody.\",\n",
        "              \"1 teaspoon of baking powder is needed in this recipe.\",\n",
        "              \"In step 1 of the directions, it says to beat the egg until fluffy.\",\n",
        "              \"You need to flip the pancakes and cook the other side when bubbles appear on the surface and begin to break.\"]"
      ],
      "metadata": {
        "id": "8u30sDG-QYur"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"The recipe does not specify the kind of food that will come out of it.\",\n",
        "              \"The recipe does not provide information about who submitted it.\",\n",
        "              \"The provided sources do not mention the specific amount of baking powder needed in this recipe.\",\n",
        "              \"The provided sources do not mention anything about using eggs in the recipe. Therefore, we cannot determine what to do with the egg based on the given information.\",\n",
        "              \"After pouring a small amount of batter into the pan and spreading it out, we need to wait for bubbles to appear on the surface and begin to break. This is the indication that it is time to turn over and cook the other side of the pancakes.\"]"
      ],
      "metadata": {
        "id": "s5UqB9fJQYxS"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTsT3lOXb7Q3",
        "outputId": "c7fb28c5-a1a1-4dc0-b183-8a201e9c6eaa"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8519, Recall: 0.8731, F1: 0.8615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpCe1zKTb7TQ",
        "outputId": "af3b4d47-1ffd-4aba-9bd1-424a189ce56d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8198, Recall: 0.8131, F1: 0.8155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tutorial 3**"
      ],
      "metadata": {
        "id": "nccg5vwqQY2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"CHICKEN LAZONE\",\n",
        "              \"Luby Luby Luby\",\n",
        "              \"4 whole boneless skinless chicken breasts\",\n",
        "              \"salt, chili powder, onion powder, garlic powder\",\n",
        "              \"Pour the cream into the skillet and lower the heat.\"]"
      ],
      "metadata": {
        "id": "KtDem5-7Qaqt"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"This recipe will result in a dish called Chicken LaZone.\",\n",
        "              \"The recipe was submitted by Luby Luby Luby.\",\n",
        "              \"The recipe calls for 4 whole boneless skinless chicken breasts.\",\n",
        "              \"The seasoning ingredients for this recipe are 1 teaspoon salt, 1 1/2 teaspoons chili powder, 1 1/2 teaspoons onion powder, and 2 teaspoons garlic powder.\",\n",
        "              \"After cooking the chicken over medium heat for about 7-8 minutes and turning it once, you need to pour the cream into the skillet and lower the heat. Then, simmer for several minutes, stirring until the sauce thickens. Finally, add the remaining butter and continue stirring until it melts.\"]"
      ],
      "metadata": {
        "id": "S5_CE-pbQbI-"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"Chicken Lazon is a dish that can be made using the provided recipe. It is a savory chicken dish with a creamy sauce. The chicken breasts are seasoned with a mixture of salt, chili powder, onion powder, and garlic powder. The chicken is then cooked in butter until it is cooked through and golden brown on the outside. After the chicken is cooked, heavy cream is added to the skillet and simmered until the sauce thickens. The remaining butter is then added to the sauce. Finally, the chicken breasts are plated and topped with the creamy sauce\",\n",
        "              \"Luby Luby Luby is the name provided as the submitter of the Chicken Lazon recipe\",\n",
        "              \"Chicken Lazon recipe requires 4 whole boneless skinless chicken breasts\",\n",
        "              \"Unable to answer as PDF/webpage could not be processed. Please wait for some time or try on a different PDF/webpage.\",\n",
        "              \"After cooking the chicken over medium heat for about 7-8 minutes and turning it once, you should check the internal temperature of the chicken to ensure it is cooked through. The internal temperature should reach 165Â°F (74Â°C) to ensure it is safe to eat. If the chicken has reached the desired temperature, you can remove it from the heat and let it rest for a few minutes before serving.\"]"
      ],
      "metadata": {
        "id": "S5qXvRGbQbMQ"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF9mL3Ksb8Kj",
        "outputId": "00ab2cd5-78c1-487a-91ff-9312e4189f6d"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8649, Recall: 0.9108, F1: 0.8867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8VFEJBEb8M6",
        "outputId": "9d93f397-e8ed-4428-9551-ddebe882545e"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8202, Recall: 0.8570, F1: 0.8377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tutorial 4**"
      ],
      "metadata": {
        "id": "gG9e7rqkQbUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"CHINESE FRIED RICE\",\n",
        "              \"PalatablePastime\",\n",
        "              \"3 drops soy sauce, and 3 drops sesame oil\",\n",
        "              \"medium grain\",\n",
        "              \"rice, green onions, and bean sprouts\"]"
      ],
      "metadata": {
        "id": "Xd_F8FifQc53"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The recipe will result in Chinese fried rice.\",\n",
        "              \"PalatablePastime submitted the recipe.\",\n",
        "              \"3 drops of soy sauce and 3 drops of sesame oil are needed.\",\n",
        "              \"The recipe suggests using cold cooked rice, preferably medium grain.\",\n",
        "              \"After pouring carrots, peas, and cooked onion into the wok, the next ingredients to add are 4 cups of cold cooked rice, grains separated (preferably medium grain), 4 green onions (chopped), and 2 cups of bean sprouts.\"]"
      ],
      "metadata": {
        "id": "GiE1P1pxQetd"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"Fried Rice is the kind of food that will come out of this recipe. It is a dish made with cooked rice, lean boneless pork or chicken, chopped vegetables such as carrots, peas, onions, green onions, and bean sprouts, and flavored with soy sauce and sesame oil. The recipe involves stir-frying the onions, cooking the egg mixture, stir-frying the meat and vegetables, adding the rice, green onions, and bean sprouts, and finally adding the chopped egg and soy sauce to the rice mixture. The dish is then stir-fried for a minute more before serving. Additional soy sauce can be added at the table if desired\",\n",
        "              \"The recipe does not mention who submitted it.\",\n",
        "              \"Soy Sauce and Sesame Oil Quantities: The recipe calls for 3 drops of soy sauce and 3 drops of sesame oil in the egg mixture. Additionally, 2 tablespoons of light soy sauce are added to the rice mixture. Please note that the provided sources do not specify the exact quantities of soy sauce and sesame oil needed for the entire recipe. The recipe suggests using more soy sauce if desired, so the amount can be adjusted according to personal preference.\",\n",
        "              \"Soy Sauce and Sesame Oil Quantities: The recipe calls for 3 drops of soy sauce and 3 drops of sesame oil in the egg mixture.\",\n",
        "              \"Ingredients to add after pouring carrots, peas, and cooked onion: Rice: Add 4 cups of cold cooked rice, grains separated (preferably medium grain). Green onions: Add 4 green onions, chopped. Bean sprouts: Add 2 cups of bean sprouts. Light soy sauce: Add 2 tablespoons of light soy sauce (add more if desired). Note: The provided recipe is for making fried rice. After pouring carrots, peas, and cooked onion, you need to add rice, green onions, bean sprouts, and light soy sauce to the mixture.\"]"
      ],
      "metadata": {
        "id": "RHgJVHtLQewK"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di0Vj6pxb9VF",
        "outputId": "d2ad378c-08dc-4840-acda-902c570f25b2"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8685, Recall: 0.9003, F1: 0.8837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOogTNRob9Xx",
        "outputId": "f818c20f-d188-433c-ab28-2ce144f971c5"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8030, Recall: 0.8316, F1: 0.8166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tutorial 5**"
      ],
      "metadata": {
        "id": "hAtswrjOQe-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"SOFT CHOCOLATE CHIP COOKIES\",\n",
        "              \"Peach\",\n",
        "              \"2\",\n",
        "              \"Yes, 2 1/4 cups flour\",\n",
        "              \"350 degrees\"]"
      ],
      "metadata": {
        "id": "2EpQm3wQQhTl"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The recipe will produce soft chocolate chip cookies.\",\n",
        "              \"Peach submitted the recipe.\",\n",
        "              \"Two eggs are needed for this recipe.\",\n",
        "              \"Yes, this recipe requires flour. It calls for 2 1/4 cups of flour.\",\n",
        "              \"The oven should be preheated to 350 degrees Fahrenheit.\"]"
      ],
      "metadata": {
        "id": "rYq8k1tlQhoI"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"Soft Chocolate Chip Cookies are the kind of food that will come out of this recipe.\",\n",
        "              \"The recipe submitter is not mentioned in the provided sources.\",\n",
        "              \"The recipe for Soft Chocolate Chip Cookies does not specify the exact number of eggs required. The provided sources do not mention the specific quantity of eggs needed for this recipe\",\n",
        "              \"The recipe for Soft Chocolate Chip Cookies does require flour, but the exact quantity is not mentioned in the provided sources.\",\n",
        "              \"The provided sources do not mention the specific temperature required for pre-heating the oven for the Soft Chocolate Chip Cookies recipe.\"]"
      ],
      "metadata": {
        "id": "E5FHEIICQhtA"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-6vHt56b-X1",
        "outputId": "8b3c00f2-af5c-4166-c64a-cfb62a8664d6"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8438, Recall: 0.8594, F1: 0.8513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fptVZCkSb-a-",
        "outputId": "be6f748f-e6cf-4b0e-a42f-17f179e55767"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8078, Recall: 0.8150, F1: 0.8110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All Data**"
      ],
      "metadata": {
        "id": "XJu6B47lQh20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground Truth\n",
        "references = [\"pip install flair\",\n",
        "              \"FLAIR framework\",\n",
        "              \"https://github.com/zalandoresearch/flair\",\n",
        "              \"Presented FLAIR as a framework designed to facilitate experimentation with different embedding types, as well as training and distributing sequence labeling and text classification models.\",\n",
        "              \"at least version 3.6 of Python\",\n",
        "              \"Edge Probing\",\n",
        "              \"Scalar Mixing Weights, and Cumulative Scoring\",\n",
        "              \"ELMo model\",\n",
        "              \"BERT model\",\n",
        "              \"to measure how well information about linguistic structure can be extracted from a pre-trained encoder\",\n",
        "              \"perform an analysis of the energy required to train a variety of popular off the-shelf NLP models, as well as a case study of the complete sum of resources required to develop LISA, a state-of-the-art NLP model from EMNLP 2018, including all tuning and experimentation.\",\n",
        "              \"Transformer base model was trained for 12 hours, and Transformer big model was trained for 3.5 days\",\n",
        "              \"Yes, Of note is that TPUs are more cost-efficient than GPUs on workloads that make sense for that hardware\",\n",
        "              \"NVIDIA Titan X GPU, and Intelâ€™s Running Average Power Limit interface CPU\",\n",
        "              \"Transformers, ELMo, BERT, GPT-2\",\n",
        "              \"brat rapid annotation tool is an intuitive web-based tool for text annotation supported by Natural Language Processing (NLP) technology\",\n",
        "              \"well-over 50,000 annotations\",\n",
        "              \"http://brat.nlplab.org\",\n",
        "              \"client-server architecture with communication over HTTP using JavaScript Object Notation (JSON)\",\n",
        "              \"15.4%\",\n",
        "              \"TextAttack\",\n",
        "              \"https://github.com/QData/TextAttack.\",\n",
        "              \"Proceedings of the 2020 Association for Computational Linguistics.\",\n",
        "              \"Yes, TextAttack is available as a Python package installed from PyPI\",\n",
        "              \"textattack attack\",\n",
        "              \"The Korean War ended in 1953\",\n",
        "              \"Kim said inter-Korean relations had become â€œa relationship between two hostile countries and two belligerents at war,â€ the state-run news agency KCNA reported\",\n",
        "              \"January 1, 2024\",\n",
        "              \"Hoo Chiew-Ping\",\n",
        "              \"three\",\n",
        "              \"The waiting migrants feel desperate\",\n",
        "              \"9,600 migrant encounters\",\n",
        "              \"1,000 migrants arrived\",\n",
        "              \"3,800 in Tijuana, 3,273 in Reynosa, and 4,000 in Matamoros\",\n",
        "              \"445,000\",\n",
        "              \"active Pacific storm track typical of an El NiÃ±o winter will send a series of storms across the US into next week\",\n",
        "              \"Thursday evening\",\n",
        "              \"Heavy precipitation will spread across the Southeast/Mid-Atlantic and possibly the Northeast this coming weekend, with increasing potential for heavy snow to the north and west of the low\",\n",
        "              \"Northeast and mid-Atlantic\",\n",
        "              \"2.3 inches fell during the entirety of 2023\",\n",
        "              \"stabbed in the neck\",\n",
        "              \"Lee was touring the construction site of the Gadeokdo New Airport and talking to reporters when he was attacked\",\n",
        "              \"Lee suffered â€œsuspected damage to his jugular veinâ€ and doctors were concerned he may have additional bleeding\",\n",
        "              \"Lee Jae-myung\",\n",
        "              \"18 cm or 7 inch\",\n",
        "              \"Japan Airlines said four of its passengers were taken to hospitals but the airline has not received any additional reports of injuries\",\n",
        "              \"Japan Airlines,  and The French aviation agency\",\n",
        "              \" Japan Coast Guard aircraft\",\n",
        "              \"five dead, 379 evacuated\",\n",
        "              \"Airbus A350-900 aircraft\",\n",
        "              \"Inflation slowed to a 3.1% annual rate in November\",\n",
        "              \"December 12, 2023\",\n",
        "              \"gasoline fell 6% and fuel oil was off 2.7%\",\n",
        "              \"2.3%\",\n",
        "              \"0.1%\",\n",
        "              \"Nvidia to launch slower version of its gaming chip in China to comply with U.S. export controls\",\n",
        "              \"December 29, 2023\",\n",
        "              \"11%\",\n",
        "              \"Yes, Nvidia RTX 4090 was included on the list of banned U.S made chips\",\n",
        "              \" rush of demand for AI, OpenAIâ€™s ChatGPT chatbot.\",\n",
        "              \"Unemployment among Asian workers and Black men rises in November while the overall rate declines\",\n",
        "              \"December 8, 2023\",\n",
        "              \"LISA KAILAI HAN\",\n",
        "              \"0.2% \",\n",
        "              \"That uptick in unemployment is not because more Asian workers are flooding into the labor market, feeling optimistic about getting jobs. Itâ€™s actually accompanied by a fall in participation as well as a fall in employment\",\n",
        "              \"Tesla reported delivery and production numbers for the fourth quarter\",\n",
        "              \"January 2, 2024\",\n",
        "              \"Total deliveries Q4 2023 is 484.507,  Total production Q4 2023 is 494.989, Total annual deliveries 2023 is 1.808.581, Total annual production 2023 is 1.845.985\",\n",
        "              \"1.31 million deliveries, and 1.37 million production\",\n",
        "              \"3.02 million\",\n",
        "              \"Copper could skyrocket over 75% to record highs by 2025 â€” brace for deficits, analysts say\",\n",
        "              \"January 2, 2024\",\n",
        "              \"LEE YING SHAN\",\n",
        "              \"$8,559 a ton\",\n",
        "              \"Rising demand driven by the green energy transition and a likely decline in the U.S. dollar in the second half of 2024\",\n",
        "              \"BOURBON CHICKEN\",\n",
        "              \"LinMarie\",\n",
        "              \"2 lbs\",\n",
        "              \"yes\",\n",
        "              \"1/2 cup\",\n",
        "              \"PANCAKES\",\n",
        "              \"Ellen Brody\",\n",
        "              \"1 teaspoon\",\n",
        "              \"Beat the egg until fluffy\",\n",
        "              \"When bubbles appear on surface and begin to break\",\n",
        "              \"CHICKEN LAZONE\",\n",
        "              \"Luby Luby Luby\",\n",
        "              \"4 whole boneless skinless chicken breasts\",\n",
        "              \"salt, chili powder, onion powder, garlic powder\",\n",
        "              \"Pour the cream into the skillet and lower the heat.\",\n",
        "              \"CHINESE FRIED RICE\",\n",
        "              \"PalatablePastime\",\n",
        "              \"3 drops soy sauce, and 3 drops sesame oil\",\n",
        "              \"medium grain\",\n",
        "              \"rice, green onions, and bean sprouts\",\n",
        "              \"SOFT CHOCOLATE CHIP COOKIES\",\n",
        "              \"Peach\",\n",
        "              \"2\",\n",
        "              \"Yes, 2 1/4 cups flour\",\n",
        "              \"350 degrees\"]"
      ],
      "metadata": {
        "id": "99R97IGBQmCy"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi RAG\n",
        "predictions_rag = [\"The command for installing the FLAIR library is pip install flair\",\n",
        "              \"The proposed solution from this paper is the FLAIR framework. It is designed to address the challenges of working with different types of word embeddings. The framework provides a unified interface for all word embeddings and allows researchers to build a single model architecture that can make use of any type of word embedding with no additional engineering effort. It also includes convenience methods for downloading NLP research datasets, model training routines, and pre-trained models. The FLAIR framework aims to simplify the process of setting up and executing experiments in natural language processing.\",\n",
        "              \"The GitHub link for the FLAIR framework is: https://github.com/zalandoresearch/flair\",\n",
        "              \"The purpose of the presented framework, called FLAIR, is to address the challenges of using different types of word embeddings in natural language processing (NLP) tasks. The framework aims to abstract away from specific engineering challenges and provide a unified interface for all word embeddings. It allows researchers to build a single model architecture that can make use of any type of word embedding with no additional engineering effort. The framework also includes convenience methods for downloading NLP datasets, model training and hyperparameter selection routines, and a growing list of pre-trained models. Overall, the framework is designed to facilitate experimentation with different embedding types and training and distributing sequence labeling and text classification models.\",\n",
        "              \"The minimum version of Python required to set up FLAIR in the environment is Python 3.6.\",\n",
        "              \"The experiment is based on the edge probing task suite, which is used to explore how different layers of the BERT network can resolve syntactic and semantic structure within a sentence.\",\n",
        "              \"The two metrics used in this experiment are scalar mixing weights and cumulative scoring.\",\n",
        "              \"The scalar mixing technique was introduced by the ELMo model.\",\n",
        "              \"The language model used in this paper is BERT (Bidirectional Encoder Representations from Transformers), as mentioned in the text: We build on this latter line of work, focusing on the BERT model (Devlin et al., 2018).\",\n",
        "              \"The main purpose of the edge probing task suite is to explore how the different layers of the BERT network can resolve syntactic and semantic structure within a sentence. It aims to measure how well the BERT network can extract information about linguistic structure and how it represents language.\",\n",
        "              \"In this research, the authors conducted an analysis to quantify the computational and environmental costs of training deep neural network models for NLP. They performed experiments to measure the energy consumed during the training of various popular off-the-shelf NLP models. The models were trained using default settings and on specific hardware (such as NVIDIA Titan X GPU and NVIDIA GTX 1080 Ti GPUs). The authors also sampled the power consumption of the GPU and CPU during training. Additionally, they conducted a case study to estimate the complete sum of resources required to develop a state-of-the-art NLP model called LISA.\",\n",
        "              \"The training time for the Transformer base model on NVIDIA P100 GPUs is 12 hours, while the training time for the Transformer big model on NVIDIA P100 GPUs is 84 hours.\",\n",
        "              \"Yes, according to the analysis in Table 3, TPUs are more cost-efficient than GPUs for certain workloads, such as training BERT.\",\n",
        "              \"The models in this experiment were trained using a combination of NVIDIA Titan X (72%) and M40 (28%) GPUs. Unfortunately, the specific CPU used for training is not mentioned in the given context.\",\n",
        "              \"The four models used in this experiment are: Transformer: An encoder-decoder architecture primarily used for machine translation, Language models: Unsupervised multitask learners, Practical Bayesian optimization of machine learning algorithms, Linguistically-Informed Self-Attention for Semantic Role Labeling.\",\n",
        "              \"BRAT is a web-based tool for text annotation supported by Natural Language Processing (NLP) technology. It is designed to assist in manual curation efforts and increase annotator productivity using NLP techniques. BRAT allows for rich structured annotation for a variety of NLP tasks and is fully configurable to support most text annotation tasks. It supports basic annotation primitives, such as identifying text spans and assigning them types, as well as connecting annotations with binary relations. BRAT also supports n-ary associations of annotations and the marking of attributes. It includes a search feature for browsing annotations and can be extended or adapted to switch out the server or client. BRAT is available under an open-source license.\",\n",
        "              \"BRAT has been used in several ongoing annotation efforts at academic institutions and has created well-over 50,000 annotations.\",\n",
        "              \"The homepage link for the free open-source BRAT is http://brat.nlplab.org.\",\n",
        "              \"BRAT is implemented using a client-server architecture with communication over HTTP using JavaScript Object Notation (JSON). The server is a RESTful web service and the client user interface is implemented using XHTML and Scalable Vector Graphics (SVG), with interactivity implemented using JavaScript with the jQuery library. The client communicates with the server using Asynchronous JavaScript and XML (AJAX).\",\n",
        "              \"The experiment resulted in a 15.4% reduction in total annotation time.\",\n",
        "              \"The research paper proposes a framework called TextAttack.\",\n",
        "              \"The GitHub link for accessing the code and tutorials of TextAttack is: https://github.com/QData/TextAttack\",\n",
        "              \"This research paper is published in the Proceedings of the Association for Computational Linguistics.\",\n",
        "              \"Yes, TextAttack can be installed as a Python package. It can be installed from PyPI or downloaded directly from GitHub.\",\n",
        "              \"The API command-line from TextAttack that allows users to specify attacks is textattack attack\",\n",
        "              \"The Korean War ended in 1953 with an armistice.\",\n",
        "              \"Based on the news agency KCNA report, Kim Jong Un stated that North Korea will no longer engage in inter-Korean relations. He mentioned that future South Korean administrations extending an olive branch will be vehemently rejected by North Korea. Kim's statement suggests a departure from any potential reconciliation or reunification efforts between North and South Korea.\",\n",
        "              \"The news article was published on Monday, January 1, 2024.\",\n",
        "              \"Hoo Chiew-Ping, a senior fellow at the East Asian International Relations CAUCUS (EAIR) and member of the Asia Pacific Nuclear Advisory Panel (APNAP), said that the North Korean leader has been increasingly walking away from inter-Korean relations in recent years.\",\n",
        "              \"North Korea plans to add three additional spy satellites by 2024.\",\n",
        "              \"According to CaÃ±as, the waiting migrants feel desperate\",\n",
        "              \"According to the report, Federal authorities reported a seven-day average of more than 9,600 migrant encounters along the US southern border in December.\",\n",
        "              \"According to the director of a migrant shelter in Piedras Negras, about 1,000 migrants arrived by train on Monday.\",\n",
        "              \"In Tijuana, an estimated 3,800 migrants are staying in shelters. In Reynosa, there are 3,273 migrants staying in shelters. The number of migrants staying in shelters in Matamoros is not mentioned in the provided context.\",\n",
        "              \"The US Department of Homeland Security has deported or returned over 445,000 migrants since May, according to the agency's online statement.\",\n",
        "              \"The highest chance for impactful snow on the East Coast this winter is caused by an active Pacific storm track that is typical of an El NiÃ±o winter. This storm track is sending a series of storms across the US, presenting the highest chance for impactful snow so far this winter in some of the country's most populous areas on the East Coast.\",\n",
        "              \"Rain will begin Thursday evening in eastern Texas.\",\n",
        "              \"The Weather Prediction Center stated that heavy precipitation will spread across the Southeast/Mid-Atlantic and possibly the Northeast, with increasing potential for heavy snow to the north and west of the low. They also mentioned that the exact amounts and precipitation type for some major East Coast cities remain highly uncertain but need to be watched.\",\n",
        "              \"Winter may finally arrive in the Northeast and mid-Atlantic in the form of a storm.\",\n",
        "              \"According to the National Weather Service, only 2.3 inches of snow fell in Central Park during the entirety of 2023, making it the least snowy calendar year on record for New York City.\",\n",
        "              \"South Korea's main opposition party leader, Lee Jae-myung, was stabbed in the neck.\",\n",
        "              \"Lee Jae-myung was attacked during a visit to the southern city of Busan. He was attacked while touring the construction site of the Gadeokdo New Airport and talking to reporters.\",\n",
        "              \"The doctors mentioned that Lee underwent vein reconstruction surgery and is currently recovering in the intensive care unit. They also expressed concerns about potential additional bleeding and suspected damage to his jugular vein.\",\n",
        "              \"The person being stabbed is Lee Jae-myung, the main opposition party leader in South Korea.\",\n",
        "              \"The knife used by the assailant to stab Lee was 18 cm (7 inches) long.\",\n",
        "              \"The airlineâ€™s Senior Vice President Noriyuki Aoki said in a press conference Tuesday evening that four of Japan Airlines' passengers were taken to hospitals, but they have not received any additional reports of injuries.\",\n",
        "              \"Japan Airlines and the French aviation agency both participated in the investigation to determine who was responsible for the plane crash.\",\n",
        "              \"The Japan Air Lines Airbus A350 collided with a De Havilland Canada DHC-8, which was operated by the Japan Coast Guard, before catching fire.\",\n",
        "              \"Five people were killed in the incident. All 379 people on JAL flight 516 were safely evacuated from the passenger plane.\",\n",
        "              \"The airplane that caught fire after taking off from Sapporo city was an Airbus A350-900 aircraft.\",\n",
        "              \"The title of the news report is Inflation showed to a 3.1% annual rate in November\",\n",
        "              \"The news report was published on Tuesday, December 12, 2023\",\n",
        "              \"The price of gasoline has decreased by 6% and the price of fuel oil has decreased by 2.7%.\",\n",
        "              \"The decrease in energy prices helped keep inflation in check by reducing the overall cost of energy-related goods and services. Specifically, gasoline prices fell by 6% and fuel oil prices were down by 2.7%. This decline in energy prices contributed to lower overall inflation as it offset some of the price increases in other categories.\",\n",
        "              \"The consumer price index increased by 0.1% in November.\",\n",
        "              \"The title of the news report is Nvidia to launch slower version of its gaming chip in China to comply with U.S. export controls\",\n",
        "              \"The news report titled Nvidia to launch slower version of its gaming chip in China to comply with U.S. export controls was published on Friday, December 29, 2023.\",\n",
        "              \"The Nvidia RTX 4090D for Chinese consumers has 11% fewer CUDA cores than versions sold outside of China.\",\n",
        "              \"Based on the information provided, the Nvidia RTX 4090 is not explicitly mentioned as being banned in the US in the Securities and Exchange Commission filing.\",\n",
        "              \"The company, Nvidia, benefits the most from the demand in the artificial intelligence (AI) sector of the market. The rush of demand for AI, including the buzz caused by OpenAI's ChatGPT chatbot, has contributed to the significant increase in Nvidia's stock price. Additionally, the export restrictions imposed by the U.S. on China primarily target chips that enable AI applications, which indicates the importance of the AI sector for Nvidia's business.\",\n",
        "              \"The main topic of the news report is the unemployment rates among different demographic groups in the U.S., specifically focusing on the rise in unemployment among Asian workers and Black men in November, while the overall unemployment rate declined.\",\n",
        "              \"The news was published on Friday, December 8, 2023.\",\n",
        "              \"The writer of the news is Lisa Kailai Han.\",\n",
        "              \"The unemployment rate declined by 0.2% last month.\",\n",
        "              \"Elise Gould stated, That uptick in unemployment is not because more Asian workers are flooding into the labor market, feeling optimistic about getting jobs. Itâ€™s actually accompanied by a fall in participation as well as a fall in employment.\",\n",
        "              \"The main topic of the news is Tesla's delivery and production numbers, as well as their plans for future growth and their competition in the electric vehicle market.\",\n",
        "              \"The news report was published on Tuesday, January 2, 2024.\",\n",
        "              \"The key numbers from Tesla's fourth-quarter vehicle production and deliveries report for 2023 are as follows: Total deliveries Q4 2023: 484,507 Total production Q4 2023: 494,989 Total annual deliveries 2023: 1,808,581 Total annual production 2023: 1,845,985\",\n",
        "              \"In 2022, Tesla reported annual deliveries of 1.31 million electric vehicles and production of 1.37 million electric vehicles.\",\n",
        "              \"BYD sold 3.02 million new energy vehicles in 2023.\",\n",
        "              \"The title of the news report is Copper could skyrocket over 75% to record highs by 2025 â€” brace for deficits, analysts say.\",\n",
        "              \"The news report was published on Tuesday, January 2, 2024.\",\n",
        "              \"The writer who published the news report is Lee Ying Shan.\",\n",
        "              \"The last price of copper on the London Metal Exchange was $8,559 per ton.\",\n",
        "              \"According to the report by BMI, the rise in copper prices is attributed to two main factors: mining supply disruptions and higher demand for the metal. The disruptions in mining supply and the increasing demand are both fueled by the push for renewable energy. Additionally, the likely decline in the U.S. dollar in the second half of 2024 is also expected to contribute to the increase in copper prices.\",\n",
        "              \"The recipe will result in Bourbon Chicken, a dish made with bite-sized pieces of chicken cooked in a flavorful sauce made with ingredients like garlic, ginger, crushed red pepper flakes, apple juice, brown sugar, ketchup, cider vinegar, water, and soy sauce. It is typically served over hot rice.\",\n",
        "              \"The recipe for Bourbon Chicken was submitted by LinMarie.\",\n",
        "              \"The recipe calls for 2 lbs of boneless chicken breasts, but it does not specify the exact number of chicken breasts needed. The number of chicken breasts required will depend on the size of the individual chicken breasts.\",\n",
        "              \"Yes, olive oil is required for this recipe. It is used to heat in a large skillet before adding the chicken pieces.\",\n",
        "              \"The recipe calls for 1/2 cup of water.\",\n",
        "              \"The recipe is for making pancakes.\",\n",
        "              \"The recipe was submitted by Ellen Brody.\",\n",
        "              \"1 teaspoon of baking powder is needed in this recipe.\",\n",
        "              \"In step 1 of the directions, it says to beat the egg until fluffy.\",\n",
        "              \"You need to flip the pancakes and cook the other side when bubbles appear on the surface and begin to break.\",\n",
        "              \"This recipe will result in a dish called Chicken LaZone.\",\n",
        "              \"The recipe was submitted by Luby Luby Luby.\",\n",
        "              \"The recipe calls for 4 whole boneless skinless chicken breasts.\",\n",
        "              \"The seasoning ingredients for this recipe are 1 teaspoon salt, 1 1/2 teaspoons chili powder, 1 1/2 teaspoons onion powder, and 2 teaspoons garlic powder.\",\n",
        "              \"After cooking the chicken over medium heat for about 7-8 minutes and turning it once, you need to pour the cream into the skillet and lower the heat. Then, simmer for several minutes, stirring until the sauce thickens. Finally, add the remaining butter and continue stirring until it melts.\",\n",
        "              \"The recipe will result in Chinese fried rice.\",\n",
        "              \"PalatablePastime submitted the recipe.\",\n",
        "              \"3 drops of soy sauce and 3 drops of sesame oil are needed.\",\n",
        "              \"The recipe suggests using cold cooked rice, preferably medium grain.\",\n",
        "              \"After pouring carrots, peas, and cooked onion into the wok, the next ingredients to add are 4 cups of cold cooked rice, grains separated (preferably medium grain), 4 green onions (chopped), and 2 cups of bean sprouts.\",\n",
        "              \"The recipe will produce soft chocolate chip cookies.\",\n",
        "              \"Peach submitted the recipe.\",\n",
        "              \"Two eggs are needed for this recipe.\",\n",
        "              \"Yes, this recipe requires flour. It calls for 2 1/4 cups of flour.\",\n",
        "              \"The oven should be preheated to 350 degrees Fahrenheit.\"]"
      ],
      "metadata": {
        "id": "-JCGYoeRQmZz"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi typeset.io\n",
        "predictions_other = [\"The command to install the FLAIR library is pip install flair. FLAIR is a powerful natural language processing library that provides pre-trained models and tools for various NLP tasks, including named entity recognition (NER) . By running the pip install flair command, the FLAIR library and its dependencies will be automatically downloaded and installed in the Python environment . This command requires an active internet connection to access the Python Package Index (PyPI) and retrieve the FLAIR package . Once installed, FLAIR can be imported into Python scripts or notebooks using the import flair statement, allowing users to leverage its functionalities for NLP tasks, including NER in the biomedical domain.\",\n",
        "                     \"The proposed solution from the paper is a natural language processing (NLP) framework called FLAIR (Framework for Learning and Information Extraction). FLAIR utilizes state-of-the-art deep learning techniques, such as bidirectional LSTMs and contextual string embeddings, to achieve high-performance results in various NLP tasks, including named entity recognition (NER). The framework is designed to be user-friendly and provides pre-trained models and tools for NLP tasks. FLAIR offers compatibility with different operating systems, including Windows, macOS, and Linux, and requires a minimum Python version of 3.6 or higher. By installing the FLAIR library using the pip install flair command, users can access the functionalities of the framework and leverage its pre-trained models for NER and other NLP tasks.\",\n",
        "                     \"The GitHub link for the FLAIR framework is https://github.com/flairNLP/flair . The FLAIR GitHub repository provides access to the source code, documentation, and examples for using the FLAIR library in natural language processing tasks . Users can clone or download the FLAIR repository from the provided GitHub link to get the latest version of the framework . The repository contains information on how to install FLAIR, as well as tutorials and examples to help users get started with using the framework for NLP tasks . Additionally, the FLAIR GitHub repository allows users to contribute to the development of the framework by submitting issues or pull requests.\",\n",
        "                     \"The presented framework is used for natural language processing (NLP) tasks, specifically named entity recognition (NER) and other NLP tasks. The framework, called FLAIR (Framework for Learning and Information Extraction), utilizes deep learning techniques, such as bidirectional LSTMs and contextual string embeddings, to achieve high-performance results in NLP tasks. FLAIR provides pre-trained models and tools for NLP tasks, making it user-friendly and accessible for researchers and practitioners. The framework is compatible with different operating systems, including Windows, macOS, and Linux, and can be installed using the pip install flair command. The FLAIR GitHub repository (https://github.com/flairNLP/flair) contains the source code, documentation, and examples for using the FLAIR library in NLP tasks, allowing users to clone or download the repository to access the latest version of the framework. Users can contribute to the development of FLAIR by submitting issues or pull requests through the GitHub repository.\",\n",
        "                     \"The minimum Python version required to set up FLAIR in the environment is Python 3.6 or higher. FLAIR is compatible with different operating systems, including Windows, macOS, and Linux. To install FLAIR, users can use the \"\"pip install flair\"\" command, which will automatically install the required dependencies. FLAIR provides pre-trained models and tools for natural language processing (NLP) tasks, such as named entity recognition (NER).The FLAIR GitHub repository (https://github.com/flairNLP/flair) contains the source code, documentation, and examples for using the FLAIR library in NLP tasks. Users can contribute to the development of FLAIR by submitting issues or pull requests through the GitHub repository\",\n",
        "              \"The experiments in the provided papers are based on the following methods: The experiments utilize a deep learning framework called FLAIR (Framework for Learning and Information Extraction) for natural language processing (NLP) tasks. FLAIR incorporates bidirectional LSTMs and contextual string embeddings to achieve high-performance results in NLP tasks. The framework provides pre-trained models and tools for NLP tasks, making it user-friendly and accessible for researchers and practitioners. FLAIR is compatible with different operating systems, including Windows, macOS, and Linux, and can be installed using the \"\"pip install flair\"\" command. The FLAIR GitHub repository contains the source code, documentation, and examples for using the FLAIR library in NLP tasks, allowing users to clone or download the repository to access the latest version of the framework. Users can contribute to the development of FLAIR by submitting issues or pull requests through the GitHub repository.\",\n",
        "              \"Two metrics used in the experiments are precision and recall. Precision is a metric that measures the proportion of correctly predicted positive instances out of all instances predicted as positive. Recall, also known as sensitivity, measures the proportion of correctly predicted positive instances out of all actual positive instances. Precision and recall are commonly used evaluation metrics in information retrieval and machine learning tasks, including natural language processing (NLP). These metrics provide insights into the performance of the models and algorithms used in the experiments, helping to assess their effectiveness in tasks such as named entity recognition (NER) and other NLP tasks.\",\n",
        "              \"The model that introduced the scalar mixing technique is the Transformer-XL model. Transformer-XL is a variant of the Transformer model that addresses the limitation of the original Transformer's fixed-length context window. The scalar mixing technique is introduced in the context of modeling long-range dependencies in sequential data. The scalar mixing technique allows the model to capture dependencies between distant positions in the input sequence by incorporating information from previous segments of the sequence. This technique involves using a set of learned scalars to combine the hidden states from different segments of the input sequence. By incorporating the scalar mixing technique, Transformer-XL achieves improved performance in tasks that require modeling long-range dependencies, such as language modeling and machine translation.\",\n",
        "              \"The language model used in this paper is BERT (Bidirectional Encoder Representations from Transformers). BERT is a deep language model that has shown state-of-the-art performance on various natural language processing (NLP) tasks. BERT is based on the Transformer architecture and is trained with a multi-task objective, including masked language modeling and next-sentence prediction. The BERT model used in this paper is the stock BERT model, which includes both the base and large versions. The encoder weights of the BERT model are frozen in this paper, following the approach of Tenney et al. (2019), to understand the structure of the network resulting from pretraining.\",\n",
        "              \"The main purpose of edge probing is to measure how well a pre-trained encoder can extract information about linguistic structure. Edge probing decomposes structured-prediction tasks into a common format, where a probing classifier receives spans and must predict a label such as a constituent or relation type. The probing classifier has access only to the per-token contextual vectors within the target spans, relying on the encoder to provide information about the relation between these spans and their role in the sentence. Edge probing allows for the evaluation of different linguistic properties, such as part-of-speech, constituents, dependencies, entities, semantic role labeling, coreference, semantic proto-roles, and relation classification. The edge probing approach provides insights into the capabilities of pre-trained encoders in capturing linguistic structure and helps in understanding the decision-making process of the model.\",\n",
        "              \"In this research, the authors conducted an analysis to quantify the computational and environmental costs of training deep neural network models for NLP. They performed experiments to measure the energy consumed during the training of various popular off-the-shelf NLP models. The models were trained using default settings and on specific hardware (such as NVIDIA Titan X GPU and NVIDIA GTX 1080 Ti GPUs). The authors also sampled the power consumption of the GPU and CPU during training. Additionally, they conducted a case study to estimate the complete sum of resources required to develop a state-of-the-art NLP model called LISA.\",\n",
        "              \"The Transformer base model, with 65M parameters, was trained on 8 NVIDIA P100 GPUs for 12 hours . The Transformer big model, with 213M parameters, was trained on 8 NVIDIA P100 GPUs for 3.5 days (84 hours; 300k steps).\",\n",
        "              \"According to the analysis in Table 3, TPUs are more cost-efficient than GPUs on workloads that are suitable for TPUs, such as BERT models. The analysis compared the CO2 emissions and estimated cost of training models using TPUs and GPUs. The research found that training BERT on a GPU is equivalent to the carbon emissions of a trans-American flight, highlighting the substantial carbon emissions associated with training models on GPUs. However, it is important to note that the analysis in Table 3 did not include power and carbon footprint information for TPUs due to a lack of public information. Therefore, while TPUs are shown to be more cost-efficient than GPUs for certain workloads, a comprehensive comparison of their environmental costs is not available in the provided sources.\",\n",
        "              \"The models in the experiment were trained on a single NVIDIA Titan X GPU, except for the ELMo model which was trained on 3 NVIDIA GTX 1080 Ti GPUs. The GPU power consumption was sampled using the NVIDIA System Management Interface. The CPU power consumption was sampled using Intel's Running Average Power Limit interface. The research also used a combination of NVIDIA Titan X (72) and M40 (28) GPUs for model training associated with the project. The training for the Linguistically-Informed Self-Attention model spanned a period of 172 days, with various job lengths ranging from 3 minutes to 9 days.\",\n",
        "              \"The four models used in this experiment are the Transformer model, the BERT model, the ELMo model, and the Linguistically-Informed Self-Attention model.\",\n",
        "              \"BRAT is a web-based tool for text annotation that is supported by Natural Language Processing (NLP) technology. It aims to enhance annotator productivity and supports manual curation efforts. It is designed to facilitate rich structured annotation for various NLP tasks and has been used in real-world annotation projects, showing a decrease in annotation time. BRAT uses a client-server architecture with communication over HTTP using JSON. The client user interface is implemented using XHTML and SVG, with interactivity implemented using JavaScript and jQuery. The server is a RESTful web service implemented in Python. BRAT supports both the Common Gateway Interface (CGI) and FastCGI protocols for efficient response times and uses a file-based stand-off format for annotation storage, eliminating the need for database import or export. \",\n",
        "              \"BRAT has created well-over 50,000 annotations in its use at academic institutions.\",\n",
        "              \"BRAT, the free open-source tool for text annotation, can be accessed through its homepage at http://brat.nlplab.org.\",\n",
        "              \"BRAT is implemented using a web-based architecture, making it accessible through a web browser. It is supported by Natural Language Processing (NLP) technology, which assists in text annotation tasks. The tool allows for rich structured annotation and aims to increase annotator productivity through the use of NLP techniques. The main user interface of BRAT includes features such as annotation editing, which recognizes standard user interface gestures familiar from text editors and presentation software . Annotations in BRAT are created by selecting a span of text with the mouse or double-clicking on a word, and connections between annotations are made by clicking on one annotation and dragging a connection to another . BRAT has been used in the annotation of six different corpora by multiple research groups, resulting in the creation of well-over 50,000 annotations in thousands of documents comprising hundreds of thousands of words\",\n",
        "              \"The experiment showed a 15% decrease in total annotation time as a result of annotation assisted by semantic class disambiguation . This evaluation was conducted on a multicategory entity mention annotation task using pre-release versions of BRAT. The integration of a machine learning-based semantic class disambiguation system, which offered multiple outputs with probability estimates, contributed to reducing ambiguity by an average of over 75% while retaining the correct class in 99% of cases across six corpora. This improvement in annotation efficiency demonstrates the effectiveness of using NLP techniques in supporting manual curation efforts and increasing annotator productivity in text annotation tasks.\",\n",
        "              \"Framework proposed in this research paper: The research paper proposes a Python framework called TextAttack for adversarial attacks, data augmentation, and adversarial training in NLP. TextAttack is designed to build attacks using four components: a goal function, a set of constraints, a transformation, and a search method. The modular design of TextAttack allows researchers to easily construct attacks by combining novel and existing components. TextAttack provides implementations of 16 adversarial attacks from the literature and supports various models and datasets, including BERT and other transformers, and all GLUE tasks. In addition to attacks, TextAttack also includes data augmentation and adversarial training modules to improve model accuracy and robustness. The framework aims to democratize NLP by enabling anyone to try data augmentation and adversarial training on any model or dataset with just a few lines of code.\",\n",
        "              \"The code and tutorials for TextAttack can be accessed at the following link: https://github.com/QData/TextAttack\",\n",
        "              \"The research paper TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP does not mention any specific proceedings where it was published. However, it is worth noting that the paper is available on arXiv, an open-access repository for scientific papers. The authors of the paper are John Morris, Eli Lifland, Jin Yoo, Jake Grigsby, Di Jin, and Yanjun Qi. The paper introduces the TextAttack framework, which is a Python framework for adversarial attacks, data augmentation, and adversarial training in NLP. It provides implementations of 16 adversarial attacks from the literature and supports various models and datasets, including BERT and other transformers, and all GLUE tasks. The framework aims to democratize NLP by enabling researchers to easily construct attacks and improve model performance. Code and tutorials for TextAttack can be found on the GitHub repository at https://github.com/QData/TextAttack.\",\n",
        "              \"Yes, TextAttack is available as a Python package that can be installed. The TextAttack framework is designed to be easily accessible and usable by researchers. It provides a modular design that allows users to construct attacks from combinations of novel and existing components. The framework supports a variety of models and datasets, including BERT and other transformers, and all GLUE tasks. To install TextAttack, users can follow the instructions provided in the code repository on GitHub. The code and tutorials for TextAttack can be found at the following link: https://github.com/QData/TextAttack. With just a few lines of code, researchers can try data augmentation and adversarial training on any model or dataset using TextAttack.\",\n",
        "              \"TextAttack provides an API command-line interface that allows users to specify attacks. This command-line interface enables users to easily configure and launch attacks on NLP models. Users can specify the attack type, target model, and dataset, among other parameters, through the command-line interface. The API command-line interface is designed to be user-friendly and accessible, allowing researchers to quickly experiment with different attack configurations. The details of the API command-line interface and its usage can be found in the TextAttack documentation and tutorials provided on the GitHub repository.\",\n",
        "              \"The Korean War ended on July 27, 1953.\",\n",
        "              \"Kim made statements about inter-Korean relations based on news agency KCNA reports. The specific details of what Kim said about inter-Korean relations are not provided in the given abstracts and contexts.\",\n",
        "              \"The specific time of the news publication is not mentioned in the provided abstracts and contexts. The information about the time of news publication is not available in the given sources.\",\n",
        "              \"The person who stated that the North Korean leader has been increasingly walking away from inter-Korean relations in recent years is not mentioned in the provided abstracts and contexts. The specific individual who made this statement is not identified in the given sources. The abstracts and contexts do not provide information about the person who made the observation about the North Korean leader's distancing from inter-Korean relations. Unfortunately, the sources do not mention the name of the person who made the statement about the North Korean leader's decreasing involvement in inter-Korean relations.\",\n",
        "              \"The abstracts and contexts provided do not mention any specific information about North Korea's plans to add spy satellites by 2024. There is no mention of the number of spy satellites that North Korea plans to add by 2024 in the given sources. The sources do not provide any details regarding North Korea's future plans for the addition of spy satellites. Unfortunately, the abstracts and contexts do not contain any information about North Korea's intended number of spy satellites by 2024. The specific number of spy satellites that North Korea plans to add by 2024 is not mentioned in the provided sources.\",\n",
        "              \"The provided abstracts and contexts do not mention any information about CaÃ±as or their perspective on the feelings of waiting migrants. There is no reference to CaÃ±as or their insights on the emotions experienced by waiting migrants in the given sources. Unfortunately, the sources do not provide any details about CaÃ±as' observations or opinions regarding the feelings of waiting migrants. CaÃ±as' perspective on the emotions felt by waiting migrants is not mentioned in the provided abstracts and contexts. The abstracts and contexts do not contain any information about CaÃ±as' views on the experiences of waiting migrants.\",\n",
        "              \"In December, Federal authorities reported a seven-day average of more than 9,600 migrant encounters along the US southern border. This number represents a significant increase compared to the seven-day average reported on November 28, which was about 6,800 encounters. The surge of people crossing into the US from Mexico has put a strain on US border cities in recent weeks. The increase in migrant encounters highlights the ongoing challenge faced by US Customs and Border Protection (CBP) in addressing the border surge. Despite efforts to address the situation, illegal crossings continue to occur, particularly in rural areas of Arizona, fueled by bad actors pushing migrants to enter between ports of entry. The situation at the border has prompted discussions between Mexican President Andres Manuel Lopez Obrador and US officials, including Secretary of State Antony Blinken and Secretary of Homeland Security Alejandro Mayorkas. \",\n",
        "              \"The director of a migrant shelter in Piedras Negras, Mexico, reported that about 1,000 migrants arrived by train on Monday. The shelter director's statement highlights the continued arrival of large groups of migrants at the border by train. The influx of migrants has led to temporary halts in crossing due to violence in the streets of Piedras Negras. The arrival of migrants by train adds to the challenges faced by US Customs and Border Protection in managing the border surge. The situation at the border has prompted discussions between Mexican President Andres Manuel Lopez Obrador and US officials, including Secretary of State Antony Blinken and Secretary of Homeland Security Alejandro Mayorkas. The meeting between Mexican and US officials aims to address the ongoing border situation and immigration policy.\",\n",
        "              \"In Tijuana, Mexico, an estimated 3,800 migrants from countries like Mexico, Cuba, Haiti, and Venezuela are staying in shelters. In Reynosa, Mexico, another 3,273 migrants are waiting at Senda De Vida shelters. In nearby Matamoros, Mexico, about 4,000 migrants are living in camps, shelters, and abandoned homes. The total number of migrants staying in shelters in Tijuana, Reynosa, and Matamoros is approximately 11,073. These migrants are waiting on the Mexican side of the border, hoping to enter the US through legal pathways established by the Biden administration. The situation at the border has prompted discussions between Mexican President Andres Manuel Lopez Obrador and US officials, including Secretary of State Antony Blinken and Secretary of Homeland Security Alejandro Mayorkas.\",\n",
        "              \"The US Department of Homeland Security has deported or returned over 445,000 migrants since May, according to the agency's online statement. The majority of these migrants had crossed the US Southern border. The deportation and return of migrants is part of the government's efforts to address the ongoing border surge and maximize limited resources. The federal government has also closed ports of entry in multiple states and reassigned personnel to transport and process migrants. The Biden Administration temporarily suspended rail operations in Eagle Pass and El Paso, but those services have since resumed. Despite these measures, illegal crossings continue to occur, particularly in rural areas of Arizona, where bad actors are pushing migrants to enter the US southern border between ports of entry.\",\n",
        "              \"The highest chance for impactful snow this winter on the East Coast was caused by an active Pacific storm track typical of an El Nino winter, which sent a series of storms across the US. These storms crossed the southern half of the US before moving up the East Coast, presenting the highest chance for impactful snow in some of the country's most populous areas. The storm system brought heavy precipitation, and the key question was where it would fall as snow and where it would fall as rain, especially along the highly populated I-95 corridor from Washington, DC, to Boston. If even an inch of snow were to fall in this corridor, it would end significant snowless streaks for major cities that have lasted for nearly two years. The storm system was expected to bring significant snow to higher elevation areas of the Appalachians and the interior Northeast, including central Pennsylvania.\",\n",
        "              \"Rain is predicted to begin in eastern Texas on Thursday evening, according to the provided context. The rain is expected to progress with the storm's track to the east, overrunning the Southeast and parts of the mid-Atlantic with time. This storm system could cause flooding issues in the South, particularly in areas that have already experienced heavy rainfall earlier in the week. The exact track of the storm becomes less certain after it leaves the Southeast, but heavy precipitation is expected to spread across the Southeast, Mid-Atlantic, and possibly the Northeast over the coming weekend. The forecast models differ on the amount of snow that could fall and where, but there is increasing potential for heavy snow to the north and west of the low-pressure system. The storm system is part of an active Pacific storm track typical of an El Nino winter, which is bringing a series of storms across the US and presenting the highest chance for impactful snow on the East Coast this winter. \",\n",
        "              \"The Weather Prediction Center stated that heavy precipitation will spread across the Southeast, Mid-Atlantic, and possibly the Northeast over the coming weekend, with increasing potential for heavy snow to the north and west of the low-pressure system. The exact amounts and precipitation type for major East Coast cities remain highly uncertain at this point, but it is advised to monitor the situation closely. The forecast models differ on the amount of snow that could fall and where, but there is a high confidence for significant snow in higher elevation areas of the Appalachians and the interior Northeast, including central Pennsylvania. The key question is where the precipitation will fall as snow and where it will fall as rain, especially along the highly populated I-95 corridor from Washington, DC, to Boston. Even an inch of snow in this corridor would end significant snowless streaks for major cities that have lasted for nearly two years. New York City, Philadelphia, and the DC area's Dulles International Airport experienced their least snowy calendar year on record in 2023, with only 2.3 inches of snow falling in Central Park.\",\n",
        "              \"Winter may finally arrive in the Northeast and mid-Atlantic in the form of a weekend storm, bringing the potential for decent snow after nearly two years of snowless streaks. The storm's timing, intensity, and track are still uncertain, as the system responsible for it is still thousands of miles away off the West Coast of the US. The highest confidence for significant snow is in higher elevation areas of the Appalachians and the interior Northeast, including central Pennsylvania. The key question is where the precipitation will fall as snow and where it will fall as rain, especially along the highly populated I-95 corridor from Washington, DC, to Boston. Major cities like New York City, Philadelphia, and the DC area's Dulles International Airport have experienced significant snowless streaks, with New York City waiting nearly 700 days for an inch of snow in a single calendar day.\",\n",
        "              \"According to the National Weather Service, Central Park in New York City experienced its least snowy calendar year on record in 2023, with only 2.3 inches of snow falling during the entirety of the year. New York City has been waiting nearly 700 days for an inch of snow in a single calendar day. The forecast models for the upcoming weekend storm differ on the amount of snow that could fall in Central Park, but the exact amounts and precipitation type for major East Coast cities remain highly uncertain at this point. It is advised to monitor the situation closely as the storm's timing, intensity, and track are still uncertain, given that the system responsible for it is still thousands of miles away off the West Coast of the US.\",\n",
        "              \"South Korea's main opposition party leader, Lee Jae-myung, was stabbed in the neck.\",\n",
        "              \"Lee Jae-myung was attacked in the southern city of Busan. He was attacked while touring the construction site of the Gadeokdo New Airport\",\n",
        "              \"Doctors stated that Lee Jae-myung suffered a 1-centimeter laceration on the left side of his neck. They were concerned about possible damage to his jugular vein and the potential for additional bleeding. Lee underwent vein reconstruction surgery and is currently recovering in the intensive care unit \",\n",
        "              \"Lee Jae-myung, the leader of South Korea's main opposition party, was stabbed in the neck\",\n",
        "              \"The knife used by the assailant to stab Lee Jae-myung was 18 cm (7 inches) long.\",\n",
        "              \"The provided sources do not mention any press conference held by the airline's Senior Vice President Noriyuki Aoki on Tuesday evening. Therefore, it is not possible to provide any information about what he said in the press conference.\",\n",
        "              \"Participants in the investigation to determine responsibility for the plane crash: Japan Airlines: The airline is taking part in the investigation to determine responsibility for the crash. Senior Vice President of Corporate Safety and Security Tadayuki Tsutsumi: He stated that Japan Airlines is participating in the investigation. France's aviation agency: The agency is sending its own investigators to Tokyo to probe the collision as part of the investigation team opened by the Japan Transport Safety Board. Japan Transport Safety Board: They have opened an investigation team to determine responsibility for the crash. Note: The sources do not provide information about any other specific individuals or organizations participating in the investigation.\",\n",
        "              \"The Japan Air Lines Airbus A350 caught fire after colliding with a De Havilland Canada DHC-8 aircraft. Note: The provided sources do not mention any other specific details about the type of plane involved in the collision.\",\n",
        "              \"Five people were killed in the JAL flight 516 incident at Tokyo's Haneda airport. All 379 people on board JAL flight 516, including eight children under the age of two, were safely evacuated from the passenger plane. Note: The provided sources do not provide any additional information regarding the number of people who were injured in the incident.\",\n",
        "              \"The airplane that ignited after flying out of Sapporo city was an Airbus A350-900 aircraft. Note: The provided sources do not mention any other specific details about the type of airplane involved in the incident.\",\n",
        "              \"Title of the news report: Inflation slowed to a 3.1% annual rate in November\",\n",
        "              \"The provided sources do not mention the specific date of when the news report was published.\",\n",
        "              \"Gasoline and Fuel Oil Price Decrease: Gasoline prices fell by 6% in November, contributing to a decrease in energy prices. Fuel oil prices were down by 2.7% in November, further contributing to the decrease in energy prices. Note: The provided sources do not mention the percentage decrease in gasoline and fuel oil prices on an annual basis.\",\n",
        "              \"Decrease in Energy Prices and Inflation: The decrease in energy prices, specifically a 2.3% decrease, helped keep inflation in check. This was primarily driven by a 6% decrease in gasoline prices and a 2.7% decrease in fuel oil prices. The decline in energy prices contributed to overall inflation remaining relatively low. It helped offset any potential upward pressure on prices that could have resulted from other factors. The decrease in energy prices played a significant role in keeping inflation in check, as energy costs are a major component of overall consumer prices. The impact of the decrease in energy prices on inflation was evident in the consumer price index, which increased by only 0.1% in November. The decline in energy prices also contributed to the core consumer price index, which excludes volatile food and energy prices, increasing by 0.3% on the month. Overall, the decrease in energy prices helped to mitigate inflationary pressures and contributed to the stability of consumer prices.\",\n",
        "              \"Consumer Price Index Increase in November: The consumer price index (CPI) increased by 0.1% in November, according to the provided sources. This indicates a slight uptick in consumer prices during that month. The CPI measures the average change over time in the prices paid by urban consumers for a market basket of consumer goods and services. The 0.1% increase in the CPI suggests a modest rise in overall consumer prices. It is important to note that this increase is specific to the month of November and does not provide information about long-term trends in inflation. For a more comprehensive understanding of inflation, policymakers often focus on core inflation, which excludes volatile food and energy prices. The core CPI increased by 0.3% on the month, indicating a slightly higher rate of inflation when excluding these volatile components.\",\n",
        "              \"Title: Nvidia to launch slower version of its gaming chip in China to comply with U.S. export controls.\",\n",
        "              \"The news about Nvidia launching a slower version of its gaming chip in China to comply with U.S. export controls was published on an unspecified date.\",\n",
        "              \"The percentage difference in CUDA cores on the Nvidia RTX 4090D for Chinese and non-Chinese consumers is 11 fewer cores for the Chinese version\",\n",
        "              \"No, the Nvidia RTX 4090 is not explicitly mentioned as being banned in the US based on the Securities and Exchange Commission (SEC) filing. However, the export rules mentioned in the filing primarily target chips that enable AI applications, and gaming-focused processors like the Nvidia RTX 4090 are also affected as they have potential uses in artificial intelligence. Nvidia has taken steps to comply with US government export controls by launching a slower version of the chip, the Nvidia RTX 4090D, in China. The Chinese version of the chip has 11 fewer CUDA cores compared to versions sold outside of China. This modification is likely designed to ensure compliance with US export controls.\",\n",
        "              \"Nvidia benefits the most from the gaming sector of the market demand. Nvidia's RTX line of advanced gaming GPUs, including the Nvidia RTX 4090D, is designed for gaming applications. The company's CUDA architecture, which is equivalent to CPU cores, is primarily used for gaming graphics processing units (GPUs). While the export restrictions imposed by the US primarily target chips enabling AI applications, gaming-focused processors like Nvidia's RTX chips are also affected as they have potential uses in artificial intelligence. Nvidia has developed the Nvidia RTX 4090D, a slower version of its gaming chip, specifically for the Chinese market to comply with US export controls. The modification in the Chinese version of the chip includes 11 fewer CUDA cores compared to versions sold outside of China. Overall, Nvidia's gaming-focused processors, such as the Nvidia RTX 4090D, cater to the demands of the gaming sector in the market.\",\n",
        "              \"Main Topic of the News Report: Unemployment Rates among Asian Workers and Black Men in November. The overall unemployment rate declined to 3.7% in November, against a forecast of 3.9%. Asian Americans saw a 0.4 percentage-point jump in the unemployment rate to 3.5%. The unemployment rate for Black Americans held steady at 5.8%, which is the demographic with the highest jobless percentage in the U.S. The increase in unemployment among Asian workers is accompanied by a fall in participation and employment. Black Americans were hit harder by business shutdowns during the Covid-19 pandemic, with a peak unemployment rate of 16.8% in 2020. The labor market deteriorated for both Asian and Black workers in November. The overall unemployment rate declined to 3.7% in November, and the labor force participation rate ticked up to 62.8% with a surge of 532,000 workers entering the labor force.\",\n",
        "              \"The provided sources do not mention the specific date of when the news was published.\",\n",
        "              \"The news report does not provide information about the specific author or authors of the report.\",\n",
        "              \"The overall unemployment rate declined by 0.2% last month.\",\n",
        "              \"Elise Gould, senior economist at the Economic Policy Institute, told CNBC that the uptick in unemployment among Asian workers and Black men is not due to more workers entering the labor market with optimism about finding jobs. She mentioned that the increase in unemployment is accompanied by a fall in participation as well as a fall in employment. She also highlighted that the unemployment rate for Black Americans, the demographic with the highest jobless percentage in the U.S., held steady at 5.8%. Additionally, she noted that the unemployment rate for Black men age 20 or older spiked to 6.4% from October's 5.3%, while the participation rate for this cohort increased to 69.2% from 67.5%.\",\n",
        "              \"Main Topic of the News: Tesla's Fourth Quarter Deliveries and Total Deliveries for 2023. Tesla reported 485,000 deliveries for the fourth quarter of 2023, bringing the total deliveries for the year to 1.8 million. The company's CEO, Elon Musk, had previously stated that the Model Y would likely be the bestselling car in terms of unit volume for the year. Tesla implemented a strategy of slashing prices in the last quarter of 2023 to cope with economic uncertainty and shifting consumer sentiment. Tesla's biggest competitor, Chinese automaker BYD, sold 3.02 million new energy vehicles in 2023. Tesla began advertising campaigns in the second half of 2023, a departure from its previous nontraditional marketing efforts. Analysts had expected Tesla to report deliveries of 477,000 for the year-ending quarter.\",\n",
        "              \"Publication Date of the News: January 2, 2024\",\n",
        "              \"Key Numbers of Tesla's Fourth-Quarter Vehicle Production and Deliveries Report for 2023: Tesla reported 485,000 deliveries for the fourth quarter of 2023, bringing the total deliveries for the year to 1.8 million. Tesla produced 476,777 Model 3 and Model Y vehicles during the quarter and reported 461,538 deliveries for these models. The company did not provide specific production or delivery numbers for the Model S or Model X, instead categorizing them as Other Models. It produced 18,212 other models and delivered 22,969 during the quarter. Note: The sources do not provide a breakdown of delivery and production numbers by individual model, so the specific numbers for the Model Y, Model S, and Model X are not available.\",\n",
        "              \"Tesla's report for 2022 does not exist in the provided sources.\",\n",
        "              \"Chinese automaker BYD sold 3.02 million new energy vehicles in 2023. Of these, 1.6 million were battery-electric passenger cars, and 1.4 million were hybrid electric models. BYD's sales figures indicate a significant presence in the new energy vehicle market, highlighting the company's commitment to sustainable transportation solutions\",\n",
        "              \"Title of the news report: Copper could skyrocket over 75% to record highs by 2025 - brace for deficits, analysts say Copper is headed for a price spurt over the next two years, as mining supply disruptions coincide with higher demand for the metal. Copper prices on the London Metal Exchange last saw an all-time record high of 10,730 per ton in March last year.\",\n",
        "              \"The news report does not provide the specific date of publication.\",\n",
        "              \"The information provided does not mention the name of the writer or author who published the news report.\",\n",
        "              \"The last price of copper on the London Metal Exchange was 8,559 per ton\",\n",
        "              \"According to a report by BMI, a Fitch Solutions research unit, the following factors caused copper prices to rise: Mining supply disruptions: The report highlights that mining supply disruptions have contributed to the increase in copper prices. Higher demand driven by the green energy transition: The push for renewable energy has led to a rise in demand for copper, as it is a key component in renewable energy infrastructure. The report suggests that this increased demand has played a significant role in driving up copper prices. Decline in the U.S. dollar strength: The report predicts a likely decline in the strength of the U.S. dollar in the second half of 2024. A weaker U.S. dollar makes copper, priced in greenbacks, more attractive to foreign buyers, further supporting the increase in copper prices. The report also mentions that the positive view for copper is more influenced by macro factors such as potential Fed rate cuts and a weaker U.S. dollar.\",\n",
        "              \"Food Type: Chicken dish. The recipe calls for boneless chicken breasts, which are cut into bite-size pieces and cooked with olive oil.\",\n",
        "              \"There is no information available in the provided sources about who submitted the recipe.\",\n",
        "              \"Number of chicken breasts needed: The recipe calls for 2 lbs of boneless chicken breasts, cut into bite-size pieces.\",\n",
        "              \"Yes, the recipe calls for 1-2 tablespoons of olive oil to be used in cooking the chicken breasts.\",\n",
        "              \"The provided sources do not mention the amount of water needed in the recipe. Therefore, we cannot determine the exact amount of water required based on the given information. Please note that the sources provided do not mention the specific details about the amount of water needed in the recipe. It is possible that the recipe does not require water or that the amount of water needed is not mentioned in the sources provided. To find the exact amount of water needed, it would be helpful to refer to other sources or recipe variations that provide this information.\",\n",
        "              \"The recipe does not specify the kind of food that will come out of it.\",\n",
        "              \"The recipe does not provide information about who submitted it.\",\n",
        "              \"The provided sources do not mention the specific amount of baking powder needed in this recipe.\",\n",
        "              \"The provided sources do not mention anything about using eggs in the recipe. Therefore, we cannot determine what to do with the egg based on the given information.\",\n",
        "              \"After pouring a small amount of batter into the pan and spreading it out, we need to wait for bubbles to appear on the surface and begin to break. This is the indication that it is time to turn over and cook the other side of the pancakes.\",\n",
        "              \"Chicken Lazon is a dish that can be made using the provided recipe. It is a savory chicken dish with a creamy sauce. The chicken breasts are seasoned with a mixture of salt, chili powder, onion powder, and garlic powder. The chicken is then cooked in butter until it is cooked through and golden brown on the outside. After the chicken is cooked, heavy cream is added to the skillet and simmered until the sauce thickens. The remaining butter is then added to the sauce. Finally, the chicken breasts are plated and topped with the creamy sauce\",\n",
        "              \"Luby Luby Luby is the name provided as the submitter of the Chicken Lazon recipe\",\n",
        "              \"Chicken Lazon recipe requires 4 whole boneless skinless chicken breasts\",\n",
        "              \"Unable to answer as PDF/webpage could not be processed. Please wait for some time or try on a different PDF/webpage.\",\n",
        "              \"After cooking the chicken over medium heat for about 7-8 minutes and turning it once, you should check the internal temperature of the chicken to ensure it is cooked through. The internal temperature should reach 165Â°F (74Â°C) to ensure it is safe to eat. If the chicken has reached the desired temperature, you can remove it from the heat and let it rest for a few minutes before serving.\",\n",
        "              \"Fried Rice is the kind of food that will come out of this recipe. It is a dish made with cooked rice, lean boneless pork or chicken, chopped vegetables such as carrots, peas, onions, green onions, and bean sprouts, and flavored with soy sauce and sesame oil. The recipe involves stir-frying the onions, cooking the egg mixture, stir-frying the meat and vegetables, adding the rice, green onions, and bean sprouts, and finally adding the chopped egg and soy sauce to the rice mixture. The dish is then stir-fried for a minute more before serving. Additional soy sauce can be added at the table if desired\",\n",
        "              \"The recipe does not mention who submitted it.\",\n",
        "              \"Soy Sauce and Sesame Oil Quantities: The recipe calls for 3 drops of soy sauce and 3 drops of sesame oil in the egg mixture. Additionally, 2 tablespoons of light soy sauce are added to the rice mixture. Please note that the provided sources do not specify the exact quantities of soy sauce and sesame oil needed for the entire recipe. The recipe suggests using more soy sauce if desired, so the amount can be adjusted according to personal preference.\",\n",
        "              \"Soy Sauce and Sesame Oil Quantities: The recipe calls for 3 drops of soy sauce and 3 drops of sesame oil in the egg mixture.\",\n",
        "              \"Ingredients to add after pouring carrots, peas, and cooked onion: Rice: Add 4 cups of cold cooked rice, grains separated (preferably medium grain). Green onions: Add 4 green onions, chopped. Bean sprouts: Add 2 cups of bean sprouts. Light soy sauce: Add 2 tablespoons of light soy sauce (add more if desired). Note: The provided recipe is for making fried rice. After pouring carrots, peas, and cooked onion, you need to add rice, green onions, bean sprouts, and light soy sauce to the mixture.\",\n",
        "              \"Soft Chocolate Chip Cookies are the kind of food that will come out of this recipe.\",\n",
        "              \"The recipe submitter is not mentioned in the provided sources.\",\n",
        "              \"The recipe for Soft Chocolate Chip Cookies does not specify the exact number of eggs required. The provided sources do not mention the specific quantity of eggs needed for this recipe\",\n",
        "              \"The recipe for Soft Chocolate Chip Cookies does require flour, but the exact quantity is not mentioned in the provided sources.\",\n",
        "              \"The provided sources do not mention the specific temperature required for pre-heating the oven for the Soft Chocolate Chip Cookies recipe.\"]"
      ],
      "metadata": {
        "id": "9_1zwqUMQmce"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : RAG x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_rag, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q28Hz4jb_vo",
        "outputId": "5431b195-f96b-41e3-e659-40cc676c0b72"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8522, Recall: 0.9010, F1: 0.8756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore : Others x Ground Truth\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='roberta-large')\n",
        "P, R, F1 = scorer.score(predictions_other, references)\n",
        "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrvoAfeub_x-",
        "outputId": "5fb3de19-2be9-4121-84c5-f01ccf473fb9"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision: 0.8161, Recall: 0.8632, F1: 0.8384\n"
          ]
        }
      ]
    }
  ]
}